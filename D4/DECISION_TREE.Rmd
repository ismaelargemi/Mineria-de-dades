---
output: pdf_document
header-includes:
- \usepackage{fullpage} 
- \usepackage[spanish]{babel}
- \setlength{\headsep}{7mm} 
- \usepackage[linktoc=page]{hyperref}
- \usepackage{fancyhdr}
- \usepackage{floatrow}
- \floatsetup[figure]{capposition=top}
- \floatsetup[table]{style=plaintop}
- \usepackage{float}
- \floatplacement{figure}{H}
- \newcommand{\beginsupplement}{
  \setcounter{table}{45}  
  \renewcommand{\thetable}{\arabic{table}} 
  \setcounter{figure}{121} 
  \renewcommand{\thefigure}{\arabic{figure}}}
- \setlength{\headheight}{13.6pt}
- \setlength{\topmargin}{-10mm}
- \rhead{Minería de Datos}
- \lhead{Entrega D4}
---

Notas:
- Hace falta balancear las variables numéricas de la base de datos??????


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{=tex}
\cfoot{\thepage}
\setcounter{page}{141}
```

\beginsupplement


## Árboles de Decisión

Siguiendo con los modelos discriminantes, en este apartado se analizará el algoritmo de los Árboles de Decisión, CART en adelante, con el mismo propósito específico: la clasificación de clientes en categorías de riesgo crediticio. En particular, nos enfocaremos en discendir entre aquellos clientes que puedan tener dificultades de pago y aquellos que son financieramente solventes.

El algoritmo de Árboles de Decisión se revela como una herramienta particularmente poderosa en este contexto, ya que su capacidad para modelar relaciones complejas entre variables puede proporcionar insights para la toma de decisiones financieras. Exploraremos cómo el algoritmo selecciona de manera inteligente las variables más influyentes para segmentar eficientemente el conjunto de datos, permitiendo la identificación de patrones que podrían indicar riesgos financieros. 


#### Algoritmo 

En este contexto, la estructura de un Árbol de Decisión se modela de forma análoga a un proceso de decisiones estratégicas:

- Cada nodo interno del árbol representa una evaluación crítica sobre un atributo financiero específico. Estas evaluaciones sirven como puntos clave para discernir las distintas condiciones financieras de los clientes.

- Las ramas que se desprenden de cada nodo interno representan las diferentes trayectorias que un cliente puede seguir según el resultado de la evaluación realizada en ese nodo.

- Las hojas del árbol en el contexto financiero contienen la información crucial: la etiqueta o el valor predicho relacionado con la capacidad del cliente para afrontar compromisos financieros. Esto puede manifestarse como una clasificación de riesgo, como "solvente" o "en riesgo", proporcionando una guía clara para las decisiones crediticias.


Así pues, a continuación se procede a realizar dicho análisis discriminante.


### Desarrollo del CART

```{r, include = F, warning=F, include=F}
library(rpart)
library(rpart.plot)
library(tree)
library(MASS)
library(dplyr)
library(withr)
library(kableExtra)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(pROC)
library(doBy)
library(caret)
library(ROSE)
library(ggplot2)
```

```{r, include = F}
load("Dades noves (balancejada i no balancejada).RData")
```

```{r, warning=FALSE, echo=FALSE, fig.cap = "Evolución de la precisión (obtenida mediante validación cruzada) dependiendo del parámetro de complejidad", fig.show='hold',out.width="75%",out.height="75%"}

# TRAINING
#Fit the model on the training set
set.seed(123)

model2 <- train(
  TARGET ~., data=train_balanceado, method = "rpart",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
)


results <- as.data.frame(model2$results)

# TEST
# Ajustar el modelo para varios valores de cp
set.seed(123)
cp_values <- c(0.007812500, 0.008064516, 0.008568548, 
               0.009072581, 0.012096774, 0.016633065, 
               0.017137097, 0.017641129, 0.026713710, 
               0.072832661)  
accuracies <- numeric(length(cp_values))

for (i in seq_along(cp_values)) {
  model <- train(
    TARGET ~., data = train_balanceado, method = "rpart",
    trControl = trainControl("cv", number = 10),
    tuneLength = 1,  # Usa 1 ya que estamos ajustando solo un hiperparámetro
    tuneGrid = data.frame(cp = cp_values[i])
  )
  
  predictions <- predict(model, newdata = validation_balanceado)
  accuracies[i] <- confusionMatrix(predictions, validation_balanceado$TARGET)$overall["Accuracy"]
}

# Crear un data frame con los resultados
results_df <- data.frame(cp = cp_values, Accuracy = accuracies)

# Plot the accuracy vs different values of cp (complexity parameter)
ggplot() +
  geom_line(data = results, aes(x = cp, y = Accuracy, color = "Train")) +
  geom_point(data = results, aes(x = cp, y = Accuracy, color = "Train")) +
  geom_line(data = results_df, aes(x = cp, y = Accuracy, color = "Test")) +
  geom_point(data = results_df, aes(x = cp, y = Accuracy, color = "Test")) +
  labs(title = "Accuracy vs Complexity Parameter",
       x = "Complexity Parameter (cp)",
       y = "Accuracy") +
  scale_color_manual(name = "Data", values = c("Train" = "blue", "Test" = "red")) +
  theme_minimal()
```


```{r, warning=FALSE, echo=FALSE, fig.cap = "Árbol de clasificación de la variable TARGET, obtenido con la complejidad "óptima"", fig.show='hold',out.width="75%",out.height="75%"}

# Grafica el árbol de decisión
rpart.plot(model2$finalModel, box.palette = "auto", shadow.col = "gray", nn = TRUE)

```



```{r, echo=F, fig.cap = "Importancia de las variables en CART", fig.show='hold',out.width="75%",out.height="75%"}
var_imp <- varImp(model2)

# Graficar las variables importantes
plot(var_imp, top=20)
```

```{r, include=FALSE}
pred <- predict(model2, newdata = validation_balanceado)

MC <- confusionMatrix(pred, validation_balanceado$TARGET, positive = "1")

tabla_cart = MC$table

rownames(tabla_cart) = c("No moroso","Potencial moroso")
colnames(tabla_cart) = c("No moroso","Potencial moroso")
```

```{r, echo=F, warning = F, fig.cap = "Matriz de confusión sobre el conjunto dde validación CART", fig.show='hold',out.width="75%",out.height="75%"}
kbl(tabla_cart,
    caption = "Matriz de confusión del conjunto de validación",
    booktabs=T)%>% 
  kable_styling(position = "center", 
                latex_options = c("HOLD_position")) %>%
    add_header_above(c("","Realidad" = 2)) %>%
   pack_rows(index=c("Predicción"=2))
```

```{r, echo=F, warning = F,fig.cap = "Resumen de Medidas de Validación para CART", fig.show='hold',out.width="75%",out.height="75%"}
Valores <- c(MC$byClass["Sensitivity"], MC$byClass["Specificity"], MC$byClass["Recall"], MC$byClass["F1"], MC$byClass["Precision"])
tabla_validacion <- as.data.frame(Valores)

kbl(tabla_validacion, caption = "Medidas de Validación para el modelo CART", booktabs=T)%>% 
                kable_styling(position = "center", 
                latex_options = c("HOLD_position"))
```
# ```{r}
# model3 <- train(
#   TARGET ~., data=train_balanceado, method = "rpart",
#   trControl = trainControl("cv", number = 10, selectionFunction = "oneSE"),
#   tuneLength = 10
# )
# rpart.plot(model3$finalModel)
# ```
