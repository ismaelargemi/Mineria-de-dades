---
output: pdf_document
header-includes:
- \usepackage{fullpage} 
- \usepackage[spanish]{babel}
- \setlength{\headsep}{7mm} 
- \usepackage[linktoc=page]{hyperref}
- \usepackage{fancyhdr}
- \usepackage{floatrow}
- \floatsetup[figure]{capposition=top}
- \floatsetup[table]{style=plaintop}
- \usepackage{float}
- \floatplacement{figure}{H}
- \newcommand{\beginsupplement}{
  \setcounter{table}{45}  
  \renewcommand{\thetable}{\arabic{table}} 
  \setcounter{figure}{121} 
  \renewcommand{\thefigure}{\arabic{figure}}}
- \setlength{\headheight}{13.6pt}
- \setlength{\topmargin}{-10mm}
- \rhead{Minería de Datos}
- \lhead{Entrega D4}
---

Notas:
- Hace falta balancear las variables numéricas de la base de datos??????

bertita:
- comentari a tot
- LLEGIR GRAFIC IMPORTANCIA VAR
- TIENE SENTIDO QUE HOJAS DEL ARBOL ACUMULEN UN 0% DE INDIVIDUOS? MÁS PRUNNING? COM0?

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{=tex}
\cfoot{\thepage}
\setcounter{page}{141}
```

\beginsupplement


## Árboles de Decisión

Siguiendo con los modelos discriminantes, en este apartado se analizará el algoritmo de los Árboles de Decisión, CART en adelante, con el mismo propósito específico: la clasificación de clientes en categorías de riesgo crediticio. En particular, nos enfocaremos en discendir entre aquellos clientes que puedan tener dificultades de pago y aquellos que son financieramente solventes.

El algoritmo de Árboles de Decisión se revela como una herramienta particularmente poderosa en este contexto, ya que su capacidad para modelar relaciones complejas entre variables puede proporcionar insights para la toma de decisiones financieras. Exploraremos cómo el algoritmo selecciona de manera inteligente las variables más influyentes para segmentar eficientemente el conjunto de datos, permitiendo la identificación de patrones que podrían indicar riesgos financieros. 


#### Algoritmo 

En este contexto, la estructura de un Árbol de Decisión se modela de forma análoga a un proceso de decisiones estratégicas:

- Cada nodo interno del árbol representa una evaluación crítica sobre un atributo financiero específico. Estas evaluaciones sirven como puntos clave para discernir las distintas condiciones financieras de los clientes.

- Las ramas que se desprenden de cada nodo interno representan las diferentes trayectorias que un cliente puede seguir según el resultado de la evaluación realizada en ese nodo.

- Las hojas del árbol en el contexto financiero contienen la información crucial: la etiqueta o el valor predicho relacionado con la capacidad del cliente para afrontar compromisos financieros. Esto puede manifestarse como una clasificación de riesgo, como "solvente" o "en riesgo", proporcionando una guía clara para las decisiones crediticias.


Así pues, a continuación se procede a realizar dicho análisis discriminante.


### Desarrollo del CART

```{r, include = F, warning=F, include=F}
library(rpart)
library(rpart.plot)
library(tree)
library(MASS)
library(dplyr)
library(withr)
library(kableExtra)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(pROC)
library(doBy)
library(caret)
library(ROSE)
library(ggplot2)
library(pROC)
```

```{r, include = F}
load("Dades noves (balancejada i no balancejada).RData")
```
Para inciar el desarrollo del modelo, el primer paso es encontrar el valor óptimo del complexity parameter, o parámetro de complejidad, que controla la cantidad de ramificaciones y nodos terminales en el árbol. Este parámetro juega un papel importante en la regularización del árbol, evitando que éste se vuelva demasiado complejo y se adapte demasiado a los datos de entrenamiento, lo que podría resultar en un sobreajuste del modelo. 

Para encontrar este valor óptimo del parámetro de complejidad, se entrena el modelo con los datos balanceados de Train y se realiza un proceso de crosvalidación con 10 folds. Entonces calculamos el accuracy para cada 10 valores posibles del complexity parameter tanto para los datos train como test.
```{r, warning=FALSE, echo=FALSE, fig.cap = "Evolución de la precisión (obtenida mediante validación cruzada) dependiendo del parámetro de complejidad", fig.show='hold',out.width="75%",out.height="75%"}

# TRAINING
#Fit the model on the training set
set.seed(123)

model2 <- train(
  TARGET ~., data=train_balanceado, method = "rpart",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10,
  cp=0, plotcp cp que de menor error
)


results <- as.data.frame(model2$results)

# TEST
# Ajustar el modelo para varios valores de cp
set.seed(123)
cp_values <- c(0.007812500, 0.008064516, 0.008568548, 
               0.009072581, 0.012096774, 0.016633065, 
               0.017137097, 0.017641129, 0.026713710, 
               0.072832661)  
accuracies <- numeric(length(cp_values))

for (i in seq_along(cp_values)) {
  model <- train(
    TARGET ~., data = train_balanceado, method = "rpart",
    trControl = trainControl("cv", number = 10),
    tuneLength = 1,  # Usa 1 ya que estamos ajustando solo un hiperparámetro
    tuneGrid = data.frame(cp = cp_values[i])
  )
  
  predictions <- predict(model, newdata = validation_balanceado)
  accuracies[i] <- confusionMatrix(predictions, validation_balanceado$TARGET)$overall["Accuracy"]
}

# Crear un data frame con los resultados
results_df <- data.frame(cp = cp_values, Accuracy = accuracies)

# Plot the accuracy vs different values of cp (complexity parameter)
ggplot() +
  geom_line(data = results, aes(x = cp, y = Accuracy, color = "Train")) +
  geom_point(data = results, aes(x = cp, y = Accuracy, color = "Train")) +
  geom_line(data = results_df, aes(x = cp, y = Accuracy, color = "Test")) +
  geom_point(data = results_df, aes(x = cp, y = Accuracy, color = "Test")) +
  labs(title = "Accuracy vs Complexity Parameter",
       x = "Complexity Parameter (cp)",
       y = "Accuracy") +
  scale_color_manual(name = "Data", values = c("Train" = "blue", "Test" = "red")) +
  theme_minimal()
```
En el gráfico se observa como el primer valor del complexity parameter es el que reporta un mayor accuracy tanto para el conjunto de datos de entrenamiento como el de validación, por lo que 'r model2$bestTune' es el valor óptimo. Como el valor del accuracy es muy parecido para ambos conjuntos de datos, podemos concluir que no se produce un sobreajuste del modelo.


```{r, echo=F, fig.cap = "Importancia de las variables en CART", fig.show='hold',out.width="75%",out.height="80%"}
df<- data.frame(variable_names, importance_values)
df <-df[order(df$importance_values),]
ggplot(df, aes(x=importance_values, y = reorder(variable_names, +importance_values))) +
   geom_bar(stat="identity", color='lightblue',fill='lightblue', width = 0.6)+
  labs(title = "Importancia de variables", x="Importancia", y=NULL)
```
CÓMO SE LEE ESTE GRÁFICO DE IMPORTANCIA? ROLLO ORDEN MAGNITUD. edad en el 70% de los arboles sera la primera

### Validación del modelo

```{r, include=FALSE}
pred <- predict(model2, newdata = validation_balanceado)
pred_train<- predict(model2, newdata = train_balanceado)

MC <- confusionMatrix(pred, validation_balanceado$TARGET, positive = "1")
MC_train<- confusionMatrix(pred_train, train_balanceado$TARGET, positive = "1")

tabla_cart = MC$table

rownames(tabla_cart) = c("No moroso","Potencial moroso")
colnames(tabla_cart) = c("No moroso","Potencial moroso")
```

```{r, echo=F, warning = F, fig.cap = "Matriz de confusión sobre el conjunto dde validación CART", fig.show='hold',out.width="75%",out.height="75%"}
kbl(tabla_cart,
    caption = "Matriz de confusión del conjunto de validación",
    booktabs=T)%>% 
  kable_styling(position = "center", 
                latex_options = c("HOLD_position")) %>%
    add_header_above(c("","Realidad" = 2)) %>%
   pack_rows(index=c("Predicción"=2))
```

```{r, echo=F, warning = F,fig.cap = "Resumen de Medidas de Validación para CART", fig.show='hold',out.width="75%",out.height="75%"}
Valores <- c(MC$overall["Accuracy"],MC$byClass["Sensitivity"], MC$byClass["Specificity"], MC$byClass["Recall"], MC$byClass["F1"], MC$byClass["Precision"])
valores_train<- c(MC_train$overall["Accuracy"],MC_train$byClass["Sensitivity"], MC_train$byClass["Specificity"], MC_train$byClass["Recall"], MC_train$byClass["F1"], MC_train$byClass["Precision"])

tabla_validacion <- data.frame(
  Train = valores_train,
  Test = Valores
)
 kbl(tabla_validacion, caption = "Medidas de Validación para el modelo CART", booktabs=T)%>% 
                kable_styling(position = "center", 
                latex_options = c("HOLD_position"))

```

```{r, echo=F, warning = F, fig.cap = "Curva ROC", fig.show='hold',out.width="75%",out.height="75%"}
tree.preds <- predict(model2, newdata = validation_balanceado, type="prob")[, 2]
tree.roc <- roc(validation_balanceado$TARGET, tree.preds,auc=T,ci=T)
plot.roc(tree.roc,print.auc=T, main = "Curva ROC", col = "blue", lwd = 2)


```

### Árbol de decisión
A continuación se presenta el árbol de decisión final con el parámetro de complejidad óptimo. EXPLICAR ORDEN VARIABLES, Y LECTURA DEL ÁRBOL A NIVEL CONCEPTUAL.
```{r, warning=FALSE, echo=FALSE, fig.cap = "Árbol de clasificación de la variable TARGET, obtenido con la complejidad "óptima"", fig.show='hold',out.width="75%",out.height="75%"}
train_balanceado_levels<- train_balanceado
levels(train_balanceado_levels$TARGET)<- c("NM", "PM")
model3 <- train(
  TARGET ~., data=train_balanceado_levels, method = "rpart",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
)
# Grafica el árbol de decisión
rpart.plot(model3$finalModel, box.palette = "auto", shadow.col = "gray", nn = TRUE)

```
EL % VOL DIR % D'INDIVIDUS QUE ES TROBEN EN AQUELLA FULLA. TÉ ALGUN SENTIT QUE EN ALGUNS HI HAGI 0?