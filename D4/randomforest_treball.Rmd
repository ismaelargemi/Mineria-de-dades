---
title: "random forest"
author: "Bertita"
date: "2023-12-08"
output: html_document
---


```{r, include = F}
load("Pruebas.RData")
```

```{r}
library(caret)
library(randomForest)
library(mlbench)
library(lattice)
library(doParallel)
library(tidyverse)
library(kableExtra)
```
# Random Forest
El Random Forest, es un método que destaca por su capacidad para realizar predicciones precisas y robustas de conjuntos de datos. Utiliza un conjunto de árboles de decisión, cada uno entrenado en subconjuntos aleatorios de datos y utilizando subconjuntos aleatorios de características. Al combinar las predicciones de múltiples árboles, el Random Forest reduce el sobreajuste y mejora la generalización del modelo. Este enfoque de "ensamblado" hace que el algoritmo sea resistente al ruido y capaz de manejar conjuntos de datos grandes y complejos. Además, el Random Forest proporciona información sobre la importancia relativa de las características, lo que facilita la identificación de variables influyentes en el proceso de toma de decisiones.

## Selección de parámetros

Para llevar a cabo el Random Forest, se escogen sus dos parámetros principales:

1. **Número de árboles (`ntree`):** Este parámetro especifica la cantidad de árboles de decisión que se construirán en el bosque. Un mayor número de árboles generalmente mejora la estabilidad y la precisión del modelo, pero también aumenta el costo computacional. Sin embargo, hay un punto de rendimiento óptimo después del cual agregar más árboles puede no aportar mejoras significativas y puede conducir a un sobreajuste. 

2. **Número de características seleccionadas en cada nodo (`mtry`):** Este parámetro indica cuántas características (variables) se deben considerar al hacer una división en cada nodo de un árbol. Una elección adecuada de `mtry` es crucial para el rendimiento del modelo. Valores bajos pueden llevar a la construcción de árboles más decorados y correlacionados, aumentando el riesgo de sobreajuste. Valores altos pueden hacer que los árboles sean más similares y reducir la diversidad del bosque. 

Para encontrar los valores óptimos de ambos parámetros, se realizará un search grid para evaluar el accuracy del modelo para cada par de valores de los parámetros. Del parámetro ntree se probarán los valores 1000, 1500, 2000, 2750, 3500 y 5000. No se probará un número mayor por el alto coste computacional que supone. Del mtry, se prueban los valores del 2 al 8, ya que el valor propuesto por la literatura sería 4. Para entrenar el modelo para cada par de variables se realiza un 10-fold cross validation.


```{r, echo=F, warning = F,fig.cap = "Random Forest para pares de valores de parámetros Ntree y Mtry", fig.show='hold',out.width="75%",out.height="75%"}
cores <- makeCluster(detectCores()-1)
registerDoParallel(cores = cores)

# Manual search by creating 10 folds and repeating 3 times
control <- trainControl(method = 'cv',
                        number = 10)

# Create tunegrid with multiple mtry values
mtry_values <- c(2:8)  # Add or modify mtry values as needed
tunegrid <- expand.grid(.mtry = mtry_values)

modellist <- list()
#1000, 1500, 2000, 2750, 3500, 5000, 7500

# Train with different ntree and mtry parameters
for (ntree in c(500,1000, 1500, 2000, 2750, 3500, 5000)) {
  for (mtry in mtry_values) {
    set.seed(123)
    fit <- train(TARGET ~ .,
                 data = train_balanceado,
                 method = 'rf',
                 metric = 'Accuracy',
                 tuneGrid = data.frame(.mtry = mtry),
                 trControl = control,
                 ntree = ntree)
    key <- paste(toString(ntree), "_mtry_", toString(mtry), sep = "")
    modellist[[key]] <- fit
  }
}

# Compare results
results <- resamples(modellist)
```

```{r, fig.width=5, fig.height=6}
# Graficar los resultados de la validación cruzada repetida
dotplot(results, metric = "Accuracy", pch = 16, auto.key = list(columns = 2))
```
Se prueban los pares de variables propuestos y en este gráfico, ordenado de mayor a menor accuracy, se observa que el mayor accuracy lo presenta modelo de Random Forest con ntree=1500 y mtry=8, con valores alrededor del 80%. 

## Desarrollo del modelo y predicciones
```{r}
cm_rf_train<- modellist[["1500_mtry_8"]][["finalModel"]][["confusion"]]

# primera clase es la negativa, per això estan girats els coeficients
verdaderos_negativos_train <- cm_rf_train[1, 1]
falsos_positivos_train <- cm_rf_train[2, 1]
verdaderos_positivos_train <- cm_rf_train[2, 2]
falsos_negativos_train <- cm_rf_train[1, 2]

# Calcular Especificidad
specificity_train <- verdaderos_negativos_train / (verdaderos_negativos_train + falsos_positivos_train)

# Calcular Sensibilidad (Recall)
sensitivity_train <- verdaderos_positivos_train / (verdaderos_positivos_train + falsos_negativos_train)

# Calcular Accuracy
accuracy_train <- (verdaderos_positivos_train + verdaderos_negativos_train) / sum(cm_rf_train)

# Calcular Puntuación F1
f1_score_train <- 2 * (sensitivity_train * specificity_train) / (sensitivity_train + specificity_train)

precision_train <- verdaderos_positivos_train / (verdaderos_positivos_train + falsos_positivos_train)

```
A partir de la 10-folds cross validation del modelo escogido, en los datos de entrenamiento se obtiene un Recall de 'r sensitivity_train' y una Especificidad de 'r specificity_train'. 

A continuación se presenta la matriz de confusión del conjunto de validación en el modelo de Random Forest entrenado.

```{r, echo=F, warning = F,fig.cap = "Matriz de confusión sobre el conjunto validación Random Forest", fig.show='hold',out.width="75%",out.height="75%"}
# Train the Random Forest model
rf_model <- randomForest(x = train_balanceado[ ,-8], y = train_balanceado$TARGET, ntree = 1000, mtry=5, importance = TRUE)

# Make predictions on the test set
predictions <- predict(rf_model, newdata = validation_balanceado)

MC <- confusionMatrix(predictions, validation_balanceado$TARGET, positive = "1")

tabla_rf = MC$table

rownames(tabla_rf) = c("No moroso","Potencial moroso")
colnames(tabla_rf) = c("No moroso","Potencial moroso")
kbl(tabla_rf,
    caption = "Matriz de confusión del conjunto de validación",
    booktabs=T)%>% 
  kable_styling(position = "center", 
                latex_options = c("HOLD_position")) %>%
    add_header_above(c("","Realidad" = 2)) %>%
   pack_rows(index=c("Predicción"=2))
```
## Validación del modelo
Y a partir de las matrices de confusión de ambos conjuntos de datos train y test, se calculan las diferentes métricas de validación del modelo:
```{r, echo=F, warning = F,fig.cap = "Medidas de Validación para el modelo Random Forest", fig.show='hold',out.width="75%",out.height="75%"}
Valores <- c(MC$overall["Accuracy"],MC$byClass["Sensitivity"], MC$byClass["Specificity"], MC$byClass["F1"], MC$byClass["Precision"])
valores_train<- c(accuracy_train, sensitivity_train , specificity_train, f1_score_train, precision_train )
tabla_validacion <- data.frame(
  Train = valores_train,
  Test = Valores
)
 kbl(tabla_validacion, caption = "Medidas de Validación para el modelo Random Forest", booktabs=T)%>% 
                kable_styling(position = "center", 
                latex_options = c("HOLD_position"))

```

El modelo Random Forest es más o menos exacto en las predicciones de la variable respuesta del conjunto de datos de validación, con un accuracy del 'r MC$overall["Accuracy"]' indica que el modelo acierta en casi el 79% de las predicciones. Además, se observa que el modelo no presenta excesivo sobrajuste porque el Accuracy es aproximadamente igual para ambos conjuntos de datos train y test. Analizando los valores de la Sensibilidad y Especificidad, con un valor de Sensibilidad del 65% en el conjunto de prueba, el modelo tiene una capacidad moderada para identificar a los clientes morosos, lo que significa que el modelo está perdiendo algunas instancias de morosidad, mientras que con una Especificidad de casi el 90% tiene una capacidad significativamente más alta para identificar los clientes no morosos, este valor minimiza los falsos positivos y ayuda a evitar que clientes no morosos sean clasificados incorrectamente como morosos. Sobre el F1, con un valor del 72.56% en el conjunto de prueba, el F1 Score indica un equilibrio razonable entre precisión y sensibilidad. En problemas de morosidad, donde las consecuencias pueden ser significativas, es importante buscar un equilibrio entre identificar correctamente a los morosos y evitar clasificar incorrectamente a los no morosos. Por último, analizando la Precisión, con un valor del 82.11% en el conjunto de prueba indica que, cuando el modelo predice que un cliente es moroso, tiene una alta probabilidad de que sea correcto. Sin embargo, se debe considerar en conjunto con la sensibilidad para no pasar por alto clientes morosos.

## Variables importantes
La importancia de las variables en Random Forest se basa en cuánto contribuyen al aumento de la homogeneidad de las clases cuando se utilizan para hacer divisiones en los árboles de decisión del bosque.
```{r, echo=F, fig.cap = "Importancia de las variables en Random Forest", fig.show='hold',out.width="75%",out.height="80%"}
importance_values <- importance(rf_model, type = 1)

# Convertir los resultados a un data frame
importance_df <- data.frame(Variable = rownames(importance_values),
                             Importance = importance_values[, 1])

# Crear el gráfico con ggplot2
ggplot(importance_df, aes(x = Importance, y = reorder(Variable, +Importance))) +
  geom_point() +
  geom_segment(aes(x = 0, xend = Importance, y = Variable, yend = Variable), linetype = "dashed") +
  labs(title = "Importancia de Variables",
       x = "Importancia",
       y = "Variable") +
  theme_minimal()

```
Se consideraran las variables más importantes las primeras cuatro que se presentan en el gráfico. Se observa que la Ratio entre la anuidad del préstamo y el crédito total solicitado, el DTI (Debt-to-income) ratio (que mide la capacidad del cliente para pagar la annuity de su préstamo en relación con sus ingresos), la Ratio entre el crédito pedido y el salario anual del prestatario (también se puede contar como el número de años que se tarda en devolver el crédito) y el tipo de organización en la que trabajan, son las cuatro variables más importantes, y que por tanto influyen más en la predicción de morosidad de un cliente, en el modelo de Random Forest.
