---
title: ''
output: pdf_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Support Vector Machine (SVM)

En este apartado se aborda el modelo predictivo llamado Support Vector Machine (SVM). Se trata de un algoritmo de machine learning supervisado, y usado para funciones de clasificación y regresión.

El objetivo de SVM es el de encontrar un hiperplano que mejor separe las clases sobre los datos de nuestra variable respuesta. Para encontrar este hiperplano óptimo, el cúal separa bien nuestros datos y a la vez maximiza el margen (distancia entre hiperplano y puntos más cercanos a él de cada clase), en muchos casos hay que aumentar la dimensionalidad, llegando a dimensiones que no pueden representarse gráficamente, pero que sí permiten una correcta discriminación entre clases.

## Obtener datos

Primero, se carga la base de datos balanceada, y se estandariza para evitar problemas derivados de la diferencia de escalas entre las variables.
```{r, include = FALSE}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("Dades noves (balancejada i no balancejada).RData")
```

También se convierte la variable respuesta a factor, ya que se trata  de un problema de clasificación.
```{r, include = FALSE}
df_preprocessed <- train_balanceado
indices_numericos <- sapply(df_preprocessed, is.numeric)

# Estandarizar solo las variables numericas
df_preprocessed[, indices_numericos] <- scale(df_preprocessed[, indices_numericos])
```

```{r, include = FALSE }
df_preprocessed$TARGET <- as.factor(df_preprocessed$TARGET)
# head(df_preprocessed)
```

Es trivial el hecho de que en este caso, los datos no pueden ser separados linealmente, dado el número de variables presentes, que son `r ncol(df_preprocessed`. Por esta razón, y dependiendo de la función kernel utilizada (y de sus parámetros), SVM utilizará espacios dimensionales transformados a partir del número de variables de la base de datos inicial. En otras palabras, el kernel define la manera como los datos se transforman en el nuevo espacio dimensional, y la dimensionalidad de dicho espacio resultante quedará determinada por los parámetros del kernel.

```{r cargar librerias, include = FALSE}
# Script para cargar librerias necesarias

install_load <- function(packages){
  for (p in packages) {
    if (p %in% rownames(installed.packages())) {
      library(p, character.only=TRUE)
    } else {
      install.packages(p)
      library(p,character.only = TRUE)
    }
  }
}

requiredpackages <- c('e1071', 'LiblineaR', 'ggplot2')
install_load(requiredpackages)
```

## Encontrar los valores de los hiperparámetros C (coste) y Gamma

Para poder determinar los valores óptimos de los hiperparámetros, se debe hacer una *validación cross-fold*. Una vez se encuentren estos valores óptimos, se ejecutará el SVM con ellos para el conjunto de datos de validación. Esto nos permite obtener las métricas de rendimiento de este modelo sobre los datos, y poder compararlas con las de otros algoritmos de clasificación.
```{r}
library(e1071)
set.seed(1)
svm_cv <- tune("svm", TARGET ~ ., data = df_preprocessed, kernel = 'radial',
              ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 20),
              gamma = c(0.5, 1, 2, 3, 4, 5, 10)))
```

```{r, echo = F, fig.cap="Representación del error en función de C y Gamma", fig.show='hold', out.height="75%", out.width="75%"}
ggplot(data = svm_cv$performances, aes(x = cost, y = error, color = as.factor(gamma)))+
  geom_line() +
  geom_point() +
  labs(title = "Error de clasificación vs hiperparámetros C y gamma", color = "gamma") +
  theme_bw() +
  theme(legend.position = "bottom")
```

Con el gráfico anterior se debería poder tener una idea, a nivel visual, del valor del hiperparámetro gamma que minimiza el error. Sin embargo, en nuestro caso la conclusión no es muy clara, con multiples líneas en el gráfico solapandose. A pesar de esto, sí se pueden obtener los valores óptimos con la siguiente instrucción:
```{r}
svm_cv$best.parameters
```

Por tanto, los valores óptimos para los dos hiperparámetros son los anteriores.

A continuación se puede ver más información sobre el mejor modelo encontrado en el *cross-fold validation*.
```{r}
modelo_svm_rbf <- svm_cv$best.model
summary(modelo_svm_rbf)
```


Entonces con el mejor modelo procedemos a hacer la predicción con los datos de la base de datos de validación, para obtener las métricas del rendimiento del modelo obtenido.
```{r}
predicciones <- predict(object = modelo_svm_rbf, validation_balanceado)

caret::confusionMatrix(data = predicciones, reference = as.factor(validation_balanceado$TARGET), positive = "1")
```

