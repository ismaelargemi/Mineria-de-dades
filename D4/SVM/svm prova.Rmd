---
title: ''
output: pdf_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Support Vector Machine (SVM)

En este apartado se aborda el modelo predictivo llamado Support Vector Machine (SVM). Se trata de un algoritmo de machine learning supervisado, y usado para funciones de clasificación y regresión.

El objetivo de SVM es el de encontrar un hiperplano que mejor separe las clases sobre los datos de nuestra variable respuesta. Para encontrar este hiperplano óptimo, el cúal separa bien nuestros datos y a la vez maximiza el margen (distancia entre hiperplano y puntos más cercanos a él de cada clase), en muchos casos hay que aumentar la dimensionalidad, llegando a dimensiones que no pueden representarse gráficamente, pero que sí permiten una correcta discriminación entre clases.

## Obtener datos

Primero, se carga la base de datos balanceada, y se estandariza para evitar problemas derivados de la diferencia de escalas entre las variables.
```{r, include = FALSE}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("Pruebas.RData")
```

También se convierte la variable respuesta a factor, ya que se trata  de un problema de clasificación.
```{r, include = FALSE}
df_preprocessed <- train_balanceado
indices_numericos <- sapply(df_preprocessed, is.numeric)

# Estandarizar solo las variables numericas
df_preprocessed[, indices_numericos] <- scale(df_preprocessed[, indices_numericos])
```

```{r, include = FALSE }
df_preprocessed$TARGET <- as.factor(df_preprocessed$TARGET)
# head(df_preprocessed)
```

Es trivial el hecho de que en este caso, los datos no pueden ser separados linealmente, dado el número de variables presentes, que son `r ncol(df_preprocessed`. Por esta razón, y dependiendo de la función kernel utilizada (y de sus parámetros), SVM utilizará espacios dimensionales transformados a partir del número de variables de la base de datos inicial. En otras palabras, el kernel define la manera como los datos se transforman en el nuevo espacio dimensional, y la dimensionalidad de dicho espacio resultante quedará determinada por los parámetros del kernel.

```{r cargar librerias, include = FALSE}
# Script para cargar librerias necesarias

install_load <- function(packages){
  for (p in packages) {
    if (p %in% rownames(installed.packages())) {
      library(p, character.only=TRUE)
    } else {
      install.packages(p)
      library(p,character.only = TRUE)
    }
  }
}

requiredpackages <- c('e1071', 'LiblineaR', 'ggplot2')
install_load(requiredpackages)
library(e1071)
```

## Encontrar los valores de los hiperparámetros C (coste) y Gamma

Para poder determinar los valores óptimos de los hiperparámetros, se debe hacer una *validación cross-fold*. Una vez se encuentren estos valores óptimos, se ejecutará el SVM con ellos (es decir, el mejor modelo) para el conjunto de datos de validación. Esto nos permite obtener las métricas de rendimiento de este modelo sobre los datos, y poder compararlas con las de otros algoritmos de clasificación.

A continuación se usa la función *tune* para encontrar, dentro de una lista predefinida de valores para cada hiperparámetro, la combinación que resulte con el modelo con mejor rendimiento.
```{r}
set.seed(1)
svm_cv <- tune("svm", TARGET ~ ., data = df_preprocessed, kernel = 'radial', cross = 10,
              ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 20),
              gamma = c(0.5, 1, 2, 3, 4, 5, 10)))
```

```{r, echo = F, fig.cap="Representación del error en función de C y Gamma", fig.show='hold', out.height="75%", out.width="75%"}
ggplot(data = svm_cv$performances, aes(x = cost, y = error, color = as.factor(gamma)))+
  geom_line() +
  geom_point() +
  labs(title = "Error de clasificación vs hiperparámetros C y gamma", color = "gamma") +
  theme_bw() +
  theme(legend.position = "bottom")
```

Con el gráfico anterior se debería poder tener una idea, a nivel visual, del valor del hiperparámetro gamma que minimiza el error.En nuestro caso, la conclusión es muy clara, siendo el valor de 0.5 el que minimiza el error con mucha diferencia respecto a los demás valores. También se pueden obtener los valores óptimos con la siguiente instrucción:
```{r}
svm_cv$best.parameters
```

Por tanto, los valores óptimos para los dos hiperparámetros son los anteriores.

A continuación se puede ver más información sobre el mejor modelo encontrado en el *cross-fold validation*.
```{r}
modelo_svm_rbf <- svm_cv$best.model
summary(modelo_svm_rbf)
```

Se puede apreciar como el número de vecotres de soporte, aquellos puntos más cercanos al límite de decisión y que definen la posición del hiperplano, es elevado, contando con 2042.

Este fenómeno puede estar causado por varios motivos. Podría ser que la frontera de decisión entre las clases es inherentemente compleja, por lo que se necesitan muchos datos para representar de forma precisa la separación entre las dos clases. También podría haber ocurrido por *overfitting*, situación en la que el modelo tiene muy buen rendimiento con el conjunto de datos de entrenamiento, pero mal rendimiento con datos nuevos. El *overfitting* ocurre cuando el modelo es demasiado complejo en relación con la cantidad de datos disponibles para entrenarlo.

A pesar de esto, con el mejor modelo procedemos a hacer la predicción con la base de datos de validación, para obtener las métricas del rendimiento del modelo obtenido.
```{r, include=FALSE}
predicciones1 <- predict(object = modelo_svm_rbf, validation_balanceado)
```

A continuación se muestra la matriz de confusión para evaluar dichas métricas y la capacidad predictiva del modelo. Hace falta aclarar que en esta matriz, el 0 representa a los "No morosos" y el 1 a los "Morosos". En los comentarios subsecuentes, "negativo" es 0 y "positivo" es 1.
```{r}
caret::confusionMatrix(data = predicciones1, reference = as.factor(validation_balanceado$TARGET), positive = "1")
```

Se puede observar un accuracy del 57%, por tanto la capacidad discriminante del modelo no destaca. También se ven las métricas de sensitivity (habilidad de clasificar registros positivos de entre todos los registros que son verdaderamente positivos) y specificity (habilidad de clasificar registros negativos de entre todos los registros que son verdaderamente negativos). Sensitivity tiene un valor de 0, es decir, que ningún individuo "Moroso" se clasifica correctamente con este modelo. En cambio, specificity toma el valor de 1, significando que todos los individuos "No morosos" se clasifican correctamente.

Se vuelve a ejecutar la matriz de confusión pero con la base de datos de entrenamiento, para verificar si hay *overfitting*.
```{r}
predicciones2 <- predict(object = modelo_svm_rbf, train_balanceado)
```

```{r}
caret::confusionMatrix(data = predicciones2, reference = as.factor(train_balanceado$TARGET), positive = "1")
```
