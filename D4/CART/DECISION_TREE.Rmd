---
output: pdf_document
header-includes:
- \usepackage{fullpage} 
- \usepackage[spanish]{babel}
- \setlength{\headsep}{7mm} 
- \usepackage[linktoc=page]{hyperref}
- \usepackage{fancyhdr}
- \usepackage{floatrow}
- \floatsetup[figure]{capposition=top}
- \floatsetup[table]{style=plaintop}
- \usepackage{float}
- \floatplacement{figure}{H}
- \newcommand{\beginsupplement}{
  \setcounter{table}{72}  
  \renewcommand{\thetable}{\arabic{table}} 
  \setcounter{figure}{148} 
  \renewcommand{\thefigure}{\arabic{figure}}}
- \setlength{\headheight}{13.6pt}
- \setlength{\topmargin}{-10mm}
- \rhead{Minería de Datos}
- \lhead{Entrega D4}
---


```{=tex}
\setlength{\headheight}{13.6pt}
\setlength{\topmargin}{-10mm}
```

\pagestyle{fancy}

```{=tex}
\rhead{Mineria de Datos}
\lhead{Entrega D4}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{=tex}
\cfoot{\thepage}
\setcounter{page}{184}
```

\beginsupplement


# Árboles de Decisión

Siguiendo con los modelos predictivos, en este apartado se analizará el algoritmo de los Árboles de Decisión, CART en adelante, con el mismo propósito específico: la clasificación de clientes en categorías de riesgo crediticio. En particular, nos enfocaremos en discendir entre aquellos clientes que puedan tener dificultades de pago y aquellos que son financieramente solventes.

El algoritmo de Árboles de Decisión se revela como una herramienta particularmente poderosa en este contexto, ya que su capacidad para modelar relaciones complejas entre variables puede proporcionar insights para la toma de decisiones financieras. Exploraremos cómo el algoritmo selecciona de manera inteligente las variables más influyentes para segmentar eficientemente el conjunto de datos, permitiendo la identificación de patrones que podrían indicar riesgos financieros. 


## Algoritmo 

En este contexto, la estructura de un Árbol de Decisión se modela de forma análoga a un proceso de decisiones estratégicas:

- Cada nodo interno del árbol representa una evaluación crítica sobre un atributo financiero específico. Estas evaluaciones sirven como puntos clave para discernir las distintas condiciones financieras de los clientes.

- Las ramas que se desprenden de cada nodo interno representan las diferentes trayectorias que un cliente puede seguir según el resultado de la evaluación realizada en ese nodo.

- Las hojas del árbol en el contexto financiero contienen la información crucial: la etiqueta o el valor predicho relacionado con la capacidad del cliente para afrontar compromisos financieros. Esto puede manifestarse como una clasificación de riesgo, como "solvente" o "en riesgo", proporcionando una guía clara para las decisiones crediticias.


Así pues, a continuación se procede a realizar dicho análisis predictivo.


### Desarrollo del CART

```{r, include = F, warning=F, echo=F}
library(rpart)
library(rpart.plot)
library(tree)
library(MASS)
library(dplyr)
library(withr)
library(kableExtra)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(pROC)
library(doBy)
library(caret)
library(ROSE)
library(ggplot2)
library(pROC)
library(mlbench)
library(yardstick)
```

```{r, include = F}
load("Pruebas.RData")
```

Para inciar el desarrollo del modelo, el primer paso es encontrar el valor óptimo del complexity parameter, o parámetro de complejidad, que controla la cantidad de ramificaciones y nodos terminales en el árbol. Este parámetro juega un papel importante en la regularización del árbol, evitando que éste se vuelva demasiado complejo y se adapte demasiado a los datos de entrenamiento, lo que podría resultar en un sobreajuste del modelo. 

Entonces, para encontrar este valor óptimo del parámetro de complejidad, se entrena el modelo con los datos balanceados de Train y se realiza un proceso de crosvalidación con 10 folds. Entonces calculamos el accuracy para cada 10 valores posibles del complexity parameter tanto para los datos train como test.


```{r, warning=FALSE, echo=FALSE, fig.cap = "Evolución de la precisión (obtenida mediante validación cruzada) dependiendo del parámetro de complejidad", fig.show='hold',out.width="75%",out.height="75%"}

# TRAINING
#Fit the model on the training set
set.seed(123)

model2 <- train(
  TARGET ~., data=train_balanceado, method = "rpart",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
)



results <- as.data.frame(model2$results)

# TEST
# Ajustar el modelo para varios valores de cp
set.seed(123)

cp_values <- c(0.004153686, 0.004672897, 0.005192108, 
               0.005711319, 0.008307373, 0.008826584, 
               0.009345794, 0.016614746, 0.043613707, 
               0.057459328) 
 
accuracies <- numeric(length(cp_values))

for (i in seq_along(cp_values)) {
  model <- train(
    TARGET ~., data = train_balanceado, method = "rpart",
    trControl = trainControl("cv", number = 10),
    tuneLength = 1,  # Usa 1 ya que estamos ajustando solo un hiperparámetro
    tuneGrid = data.frame(cp = cp_values[i])
  )
  
  predictions <- predict(model, newdata = validation_balanceado)
  accuracies[i] <- confusionMatrix(predictions, validation_balanceado$TARGET)$overall["Accuracy"]
}

# Crear un data frame con los resultados
results_df <- data.frame(cp = cp_values, Accuracy = accuracies)

# Plot the accuracy vs different values of cp (complexity parameter)
ggplot() +
  geom_line(data = results, aes(x = cp, y = Accuracy, color = "Train")) +
  geom_point(data = results, aes(x = cp, y = Accuracy, color = "Train")) +
  geom_line(data = results_df, aes(x = cp, y = Accuracy, color = "Test")) +
  geom_point(data = results_df, aes(x = cp, y = Accuracy, color = "Test")) +
  labs(title = "Accuracy vs Complexity Parameter",
       x = "Complexity Parameter (cp)",
       y = "Accuracy") +
  scale_color_manual(name = "Data", values = c("Train" = "blue", "Test" = "red")) +
  theme_minimal()

```
En el gráfico se observa como el primer valor del complexity parameter es el que reporta un mayor accuracy para el conjunto de datos de entrenamiento. No obstante, no únicamente buscamos el hiperparámetro que nos aporte un mayor accuracy, sino que también nos interesa encontrar un cp con el que además de maximizar el accuracy, evitemos overffiting (sobreajuste del modelo). Así pues, observamos como el segundo valor del complexity parameter nos da un valor que no se aleja mucho del accuracy óptimo y, además, nos evita en una gran manera un overfitting. Por lo tanto, concluimos que el cp óptimo para nuestro árbol de decisión final es `r model2$results$cp[2]`.


```{r, include=FALSE}
# **model tree final**

train_balanceado_levels<- train_balanceado
levels(train_balanceado_levels$TARGET)<- c("NM", "PM")

grid <- expand.grid(
  .cp = c(model2$results$cp[2])
)

tree <- train(TARGET ~., data=train_balanceado_levels, method = "rpart",
                    metric="Accuracy", trControl=trainControl(method="none"),tuneGrid=grid)

rpart.plot(tree$finalModel)
```



### Validación del modelo

Una vez ejecutado el modelo CART, con el objetivo de validar el modelo, se muestra en una tabla la matriz de confusión y se calcula la precisión con la que el algoritmo ha predicho la variable Target tanto en la población del Train como en la del Test, para observar si ha habido un sobreajuste o no.

```{r, include=FALSE}
train_balanceado_levels<- train_balanceado
levels(train_balanceado_levels$TARGET)<- c("NM", "PM")

validation_balanceado_levels <- validation_balanceado
levels(validation_balanceado_levels$TARGET)<- c("NM", "PM")


pred <- predict(tree, newdata = validation_balanceado_levels)
pred_train<- predict(tree, newdata = train_balanceado_levels)

MC <- confusionMatrix(pred, validation_balanceado_levels$TARGET, positive = "PM")
MC_train<- confusionMatrix(pred_train, train_balanceado_levels$TARGET, positive = "PM")

tabla_cart = MC$table

rownames(tabla_cart) = c("No moroso","Potencial moroso")
colnames(tabla_cart) = c("No moroso","Potencial moroso")
```

```{r, echo=F, warning = F, fig.cap = "Matriz de confusión sobre el conjunto de validación CART", fig.show='hold',out.width="75%",out.height="75%"}
kbl(tabla_cart,
    caption = "Matriz de confusión del conjunto de validación",
    booktabs=T)%>% 
  kable_styling(position = "center", 
                latex_options = c("HOLD_position")) %>%
    add_header_above(c("","Realidad" = 2)) %>%
   pack_rows(index=c("Predicción"=2))
```



```{r, echo=F, warning = F,fig.cap = "Resumen de Medidas de Validación para CART", fig.show='hold',out.width="75%",out.height="75%"}
Valores <- c(MC$overall["Accuracy"],MC$byClass["Sensitivity"], MC$byClass["Specificity"], MC$byClass["Recall"], MC$byClass["F1"], MC$byClass["Precision"])
valores_train<- c(MC_train$overall["Accuracy"],MC_train$byClass["Sensitivity"], MC_train$byClass["Specificity"], MC_train$byClass["Recall"], MC_train$byClass["F1"], MC_train$byClass["Precision"])

tabla_validacion <- data.frame(
  Train = valores_train,
  Test = Valores
)
 kbl(tabla_validacion, caption = "Medidas de Validación para el modelo CART", booktabs=T)%>% 
                kable_styling(position = "center", 
                latex_options = c("HOLD_position"))

```


La anterior salida nos muestra la matriz de confusión junto con diversos estadísticos que tratan de explicar como de bien o mal ha predicho el algoritmo de CART. Así pues, como se observa, las medidas de validación son aproximadamente las mismas tanto para Train como para Test, por lo tanto, reafirmamos que no hay un sobreajuste en el modelo (como ya se había dicho anteriormente). 

En este caso, la precisión ha sido del `r round(MC$overall["Accuracy"],4)`%, lo que indica que el algoritmo ha predicho correctamente el `r round(MC$overall["Accuracy"]*100, 4)`% de los individuos de Test.  Esto indica que el modelo es capaz de clasificar correctamente a la mayoría de los clientes en categorías de riesgo crediticio.

La sensibilidad del modelo, que mide la capacidad de identificar clientes potencialmente morosos, es del `r round(MC$byClass["Sensitivity"]*100,4)`% en el conjunto de prueba. Esto sugiere que hay margen para mejorar en la identificación de clientes con dificultades de pago.

Por otro lado, el modelo muestra una alta especificidad, del `r round(MC$byClass["Specificity"]*100,4)`%, indicando su habilidad para identificar clientes no morosos con precisión. 

Si observamos otras métricas disponibles, apreciaremos como la precisión, que mide la exactitud de las predicciones positivas, es del `r round(MC$byClass["Precision"]*100,4)`% en el conjunto de prueba. Esto significa que cuando el modelo predice que un cliente es potencialmente moroso, es correcto en aproximadamente el 82.76% de las veces. Por último, podemos apreciar como la puntuación F1, que equilibra precisión y recuperación, es del 62.3% en el conjunto de prueba, indicandonos que el modelo logra un buen equilibrio entre la precisión de las predicciones positivas y la capacidad para recuperar casos positivos. 

En resumen, el modelo muestra un buen rendimiento general, especialmente en términos de especificidad, pero hay margen para mejorar en la identificación de clientes potencialmente morosos, como lo sugiere la sensibilidad y la puntuación F1 en ambos conjuntos. 


### Prueba ácida

```{r, include=FALSE}
train_balanceado_levels<- train_balanceado
levels(train_balanceado_levels$TARGET)<- c("NM", "PM")

validation_desbalanceado_levels <- validation_desbalanceado
levels(validation_desbalanceado_levels$TARGET)<- c("NM", "PM")


pred <- predict(tree, newdata = validation_desbalanceado_levels)
pred_train<- predict(tree, newdata = train_balanceado_levels)

MC <- confusionMatrix(pred, validation_desbalanceado_levels$TARGET, positive = "PM")
MC_train<- confusionMatrix(pred_train, train_balanceado_levels$TARGET, positive = "PM")

tabla_cart = MC$table

rownames(tabla_cart) = c("No moroso","Potencial moroso")
colnames(tabla_cart) = c("No moroso","Potencial moroso")
```

```{r, echo=F, warning = F, fig.cap = "Matriz de confusión sobre el conjunto de validación CART sobre test desbalanceado", fig.show='hold',out.width="75%",out.height="75%"}
kbl(tabla_cart,
    caption = "Matriz de confusión del conjunto de validación desbalanceado",
    booktabs=T)%>% 
  kable_styling(position = "center", 
                latex_options = c("HOLD_position")) %>%
    add_header_above(c("","Realidad" = 2)) %>%
   pack_rows(index=c("Predicción"=2))
```



```{r, echo=F, warning = F,fig.cap = "Resumen de Medidas de Validación para CART sobre test desbalanceado", fig.show='hold',out.width="75%",out.height="75%"}
Valores <- c(MC$overall["Accuracy"],MC$byClass["Sensitivity"], MC$byClass["Specificity"], MC$byClass["Recall"], MC$byClass["F1"], MC$byClass["Precision"])
valores_train<- c(MC_train$overall["Accuracy"],MC_train$byClass["Sensitivity"], MC_train$byClass["Specificity"], MC_train$byClass["Recall"], MC_train$byClass["F1"], MC_train$byClass["Precision"])

tabla_validacion <- data.frame(
  Train = valores_train,
  Test_desbalanceado = Valores
)
 kbl(tabla_validacion, caption = "Medidas de Validación con el conjunto test desbalanceado para el modelo CART", booktabs=T)%>% 
                kable_styling(position = "center", 
                latex_options = c("HOLD_position"))

```

El accuracy del modelo en el conjunto de prueba desbalanceado ha sido del `r round(MC$overall["Accuracy"],4)`%, lo que indica que el `r round(MC$overall["Accuracy"],4)`% de las predicciones fueron buenas. Sin embargo, la exactitud puede ser engañosa en conjuntos de datos desbalanceados, donde la mayoría de las observaciones pertenecen a una clase particular. Por otra parte, la sensibilidad en el conjunto de prueba desbalanceado es bastante baja, solo del 15%. Esto significa que el modelo tiene dificultades para identificar correctamente a los clientes morosos. La sensibilidad es especialmente crucial en situaciones financieras, ya que representa la capacidad del modelo para capturar la totalidad de los casos positivos (morosos) reales. En este caso, el bajo valor de sensibilidad indica que el modelo está dejando pasar un número significativo de clientes morosos sin detectarlos.

Así pues, la especificidad que mide la capacidad del modelo para identificar correctamente los casos negativos (clientes no morosos), es del 93.14%. Esto sugiere que el modelo tiene un buen rendimiento al identificar a los clientes que no son morosos. Sin embargo, es importante destacar que la alta especificidad podría deberse al desbalance en los datos, ya que hay más clientes no morosos en el conjunto de prueba.


Finalmente,  el valor de F1 es del 15.48%, lo que refleja un equilibrio entre precisión y sensibilidad. Este valor relativamente bajo sugiere que hay margen de mejora en la capacidad del modelo para identificar clientes morosos sin comprometer demasiado la precisión. De la misma manera, en cuanto a la precisión (Precision), es del 16%, lo que significa que de las instancias que el modelo predice como morosas, solo el 16% son realmente morosas. Este valor puede ser bajo, indicando que el modelo podría estar generando demasiados falsos positivos.


### Curva ROC

Para un análisis más profundo sobre la calidad de predicción del modelo, se representa la curva ROC y se interpreta su área bajo la curva (AUC).

```{r,  include=FALSE}
tree.preds <- predict(model2, newdata = validation_balanceado, type = "prob")[, 2]
tree.roc <- roc(validation_balanceado$TARGET, tree.preds, auc = TRUE, ci = TRUE)
```


```{r,  echo=F, warning = F, fig.cap = "Curva ROC", fig.show='hold',out.width="75%",out.height="75%"}
plot.roc(tree.roc, print.auc = TRUE, main = "Curva ROC", col = "blue", lwd = 2, legacy.axes = TRUE)

```

El AUC (Área Bajo la Curva) de 0.760 en la curva ROC sugiere que el modelo tiene una capacidad moderadamente buena para distinguir en la clasificación binaria entre morosos y no morosos. En otras palabras, el modelo es mejor que una clasificación aleatoria, es prometedor y sugiere que el modelo tiene un rendimiento decente en términos de discriminación. Sin embargo, hay un pequeño margen para mejorar.



## Árbol de decisión

A continuación, se presenta el árbol de decisión final con el parámetro de complejidad óptimo elegido. 

```{r, warning=FALSE, echo=FALSE, fig.cap = "Árbol de clasificación de la variable TARGET, obtenido con la complejidad 'óptima'"}

train_balanceado_levels<- train_balanceado
levels(train_balanceado_levels$TARGET)<- c("NM", "PM")


grid <- expand.grid(
  .cp = c(model2$results$cp[2])
)

tree <- train(TARGET ~., data=train_balanceado_levels, method = "rpart",
                    metric="Accuracy", trControl=trainControl(method="none"),tuneGrid=grid)


# Grafica el árbol de decisión
rpart.plot(tree$finalModel, box.palette = "auto", shadow.col = "gray", nn = TRUE, extra=101)
```


El árbol de decisión generado se inicia evaluando la edad del solicitante. Si la edad es mayor o igual a 57 años, el modelo tiende a clasificar al individuo como "No Moroso" con un accuracy del 85%. Este primer nivel de decisión sugiere que la edad es un factor determinante en la predicción de la no morosidad.

Por otro lado, dentro de la categoria de clientes más jovenes, el árbol se ramifica según el ratio anualidad/crédito (RATIO_ANNITY_CREDIT). Aquellos con un ratio inferior a 0.0295, se los clasifica como no morosos con un accuracy del 91%, sugiriendo que clientes con cargas de anualidad más bajas en comparación con su crédito son menos propensos a tener dificultades de pago. 

En contraste, para clientes con un ratio mayor o igual a 0.0295, factores adicionales como el estado civil, número de miembros familiares y educación influyen en la clasificación.

Clientes casados y con más de 2 miembros familiares tienden a tener una probabilidad de ser clasificados correctamente de no ser morosos (accuracy) de un 80%. En casos específicos, como aquellos con menos de 2 miembros familiares y educación incompleta, la probabilidad ser clasificados en clientes no morosos alcanza el 88%.

La segmentación se profundiza aún más considerando variables como la región del cliente, la ocupación y la relación anualidad/crédito. En situaciones particulares, como ocupaciones desconocidas y ratios anualidad/crédito superiores a 0.03193, la probabilidad de morosidad se incrementa significativamente (71.81%).

Este orden de variables en el árbol está determinado por la importancia relativa de cada variable en la tarea de clasificación. Las variables que ofrecen una mayor separación entre las clases son utilizadas en los niveles iniciales del árbol.


```{r, echo=F, fig.cap = "Importancia de las variables en CART", fig.show='hold',out.width="75%",out.height="80%"}
importance_values <- tree$finalModel$variable.importance
variable_names <- names(importance_values)

df<- data.frame(variable_names, importance_values)
df <-df[order(df$importance_values),]
top_10 <- tail(df, 10)

ggplot(top_10, aes(x=importance_values, y = reorder(variable_names, +importance_values))) +
   geom_bar(stat="identity", color='lightblue',fill='lightblue', width = 0.6)+
  labs(title = "Importancia de variables", x="Importancia", y=NULL)

```
La variable "CNT_FAM_MEMBERS" (Número de miembros de la familia) es la característica más influyente en la clasificación del riesgo crediticio, con una importancia relativa del 218.19%. Esto sugiere que la composición familiar tiene un impacto significativo en la capacidad de pago.

Por otro lado, el estado civil "Married" (Casado) y la relación entre la anualidad y el crédito ("RATIO_ANNUITY_CREDIT") son también factores cruciales, con importancias del 74.26% y 64.80%, respectivamente. Estos indican que el estado civil y la relación entre la anualidad y el crédito desempeñan un papel fundamental en la toma de decisiones crediticias.

Además, la "Edad" ("AGE_YEARS") del solicitante es otra variable clave, con una importancia del 57.85%. Esto refuerza la conclusión de que la edad es un factor importante en la predicción de la no morosidad.

En resumen, las variables más influyentes, como el número de miembros de la familia, estado civil, relación anualidad/crédito y edad, resaltan la importancia de aspectos fundamentales en la evaluación del riesgo. Además, factores sociodemográficos como la ubicación geográfica y la educación juegan un papel crucial en la toma de decisiones crediticias.\newline


**Conclusiones**  \newline

Como la sensibilidad obtenida ha sido mucho más baja que la especificidad, concluimos que el modelo tiene más dificultades para identificar los casos positivos reales (morosos) en comparación con su habilidad para identificar correctamente los casos negativos reales (no morosos). Este resultado no nos es beneficioso en la clasificación, ya que en este contexto quizás sea mejor detectar adecuadamente casos posotivos (morosos), para así reducir el número de clientes morosos.

Así pues concluimos que el modelo CART proporciona una herramienta valiosa para la clasificación de riesgo crediticio, destacando la importancia de variables clave como los miembros de la familia, la edad y la relación entre la anualidad y el crédito. Para mejorar aún más, es recomendable explorar ajustes en la sensibilidad y considerar otras técnicas de modelado que puedan aportar mejoras específicas para el objetivo del problema.
