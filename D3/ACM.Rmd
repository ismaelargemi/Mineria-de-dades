---
title: "ACM"
author: "Bertita"
date: "2023-10-09"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```
Comentaris:
- posar més subtítols?
- treure variable Target de l'analisi
- canviar noms variables per a evitar solapaments
- treure les variables numèriques de les suplementàries que s'hagin considerat no rellevants en l'ACP
- CAL ACABAR TOT EL QUE ESTÀ EN MAJÚSCULES, I SI VOLEU AFEGIR MÉS ANÀLISI I CANVIAR COSES CAP PROBLEMA

# ACM

```{r, include=FALSE}
library(FactoMineR)
library(factoextra)
library(Matrix)
library(ggplot2)

```

```{r, include=FALSE}
# Lectura de la base de datos
df <-get(load("Dades preprocessades.RData"))
df2<- df[1:15] 
df2 <- df2[,-8] #eliminamos la variable TARGET del análisis
```

El Multiple Correspondance Analysis, ACM en adelante, es un método de análisis factorial para variables categóricas que permite analizar relaciones entre variables, así como reducir la dimensionalidad de la base de datos seleccionando sólo aquellas variables relevantes. Para realizarlo se deben escoger unas variables activas y otras de complementarias. En este caso, como el número de variables es relativamente bajo y se consideran todas relevantes, no se considerará ninguna variable complementaria. Además, se añadirán al análisis las variables numéricas como variables suplementarias, aunque solamente aquellas que se han considerado relevantes en el ACP. 


## Desarrollo del ACM

```{r, out.width="95%"}
res.mca <- MCA(df2, quanti.sup = c(8:14), method = "Burt")
res.mca
```
En la primera figura se representan las relaciones entre las modalidades de todas las variables categóricas con las dos primeras dimensiones del MCA. Se observa que la dimensión 1 se asocia con las variables que tienen relación con la edad, como la modalidad de Pensionista y Viudo. Se aprecia que la dimensión 2 se asocia a las modalidades relacionadas con la cualificación del trabajo del individuo, con una asociación positiva entre la dimensión y la cualificación del trabajador. Por tanto, se llamará a la dimensión 1 Edad, y a la dimensión 2 como cualificiación del trabajador. 

En los gráficos obtenidos puede verse la variabilidad que expresan cada una de las variables categóricas en función de las dimensiones 1 y 2. Aquellas variables que estén más cerca del origen de coordenadas aportan muy poca información respecto a la variabilidad de los datos y, por tanto, son poco importantes. En cambio, aquellas variables más alejadas del centro aportan información más relevante.


Se representan gráficamente la inercia que explica cada una de las dimensiones generadas:
```{r, out.width="90%"}
barp <- barplot(res.mca$eig[,2], names.arg=1:nrow(res.mca$eig), ylim = c(0,21), 
                cex.names = 0.7, las = 2, xlab = c("Dimensiones"), 
                ylab = c("Percentatge de variància explicada"), 
                main = "Inercia explicada per cada dimensión")
```

Si una dimensión tiene una inercia baja, significa que todas las modalidades están muy cercanas al centro de gravedad y, en consecuencia, son muy similares. A medida que aumenta la inercia, va aumentando la distancia al centro de gravedad y, por tanto, se reduce la similitud.

Para poder estudiarlo más a fondo, se realiza la siguiente tabla en la que se puede observar para cada dimensión, su valor propio, el porcentaje de varianza (o inercia) explicada, y el porcentaje de varianza (o inercia) acumulada:

```{r}
round(res.mca$eig, 2)
```
Tenemos un total de 31 dimensiones. La dimensión 1 destaca muy por encima del resto, explicando un 20.37% de la variabilidad de los datos, seguida de la dimensión 2, explicando un 9.62% de la variabilidad de los datos los datos. A partir de la dimensión 6, se ve que la gráfica se estabiliza bastante ya hasta la última dimensión.

Por tanto, en total las dos primeras dimensiones ya explican un 29.99% de la variabilidad de los datos, y se necesitan 17 dimensiones para llegar a tener una inercia acumulada por encima del 80%. 

Aunque las primeras dos dimensiones expliquen cerca del 30% de la inercia, no todos los puntos se muestran igual de bien en las dos dimensiones. La calidad de la representación se llama coseno cuadrado (cos2), que mide el grado de asociación entre categorías de variables y un eje particular.

Si una categoría de variable está bien representada por dos dimensiones, la suma de cos2 es cercana a uno. Para algunos de los elementos de la fila, se requieren más de dos dimensiones para representar perfectamente los datos. Se considera lo siguiente:

  - Las categorías de variables con valores bajos de cos2 se colorearán en "cian".
  - Las categorías de variables con valores medios de cos2 se colorearán en “amarillo”.
  - Las categorías de variables con valores altos de cos2 se colorearán en “rojo”.


````{r}
# Color by cos2 values: quality on the factor map
fviz_mca_var(res.mca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE, # Avoid text overlapping
             ggtheme = theme_minimal())
````
Salen muchas categorías que no están muy bien representadas por las dos primeras dimensiones. Esto implica que la posición de los puntos correspondientes en el diagrama de dispersión debe interpretarse con cierta cautela. Probablemente sea necesaria una solución de mayor dimensión. Aún así, se ha decidido no realizar el MCA de mayores dimensiones debido a la dificultad de representación gráfica. Por tanto, los resultados del MCA se analizarán con cautela, especialmente las variables poco representadas en las dos primeras dimensiones.

## Plot individuos

Se representa gráficamente cómo se distribuyen los individuos en función de las dos primeras dimensiones que explican un 29.99% de la variabilidad:

```{r, out.width="95%"}
fviz_mca_ind(res.mca, geom = "point", col.ind = "black")
```
A simple vista, se aprecian varios grupos de individups pero resulta difícil distinguir cuántos. Sin embargo, sí podríamos decir que los individuos se dividen en como mínimo 2 grupos. Para distinguir mejor las agrupaciones de individuos y su asociación con algunas modalidades se pasa a estudiar cada variable para observar si existe algún tipo de asociación entre ellas.

A continuación representamos los mismos individuos pero coloreandolos según la variable "target", es decir, nuestra varible output, donde 1 indica aquel cliente con dificultades de pago, y 0 altramente:

```{r}
library(FactoMineR)

fviz_mca_ind(res.mca, geom = "point", col.ind = df_preprocessed$TARGET, 
             palette = c("blue", "red"))  # Reemplaza con los colores deseados

```
Observamos... ACABAR DE ANALIZAR

HACER EL MISMO GRÁFICO Y PINTAR LOS PNTOS CON VAR TARGET. Si cuadra con los grupos de individuos, se podría hacer profiling a partir de este ACM. Segurament no, però ho podem fer i dir que no es veuen associacions clares entre la variable TARGET i les modalitats de les variables ben representades en aquest parell de dimensions.

## Plot variables

```{r}
# Totes les variables actives
newbd<- df[1:7]
res.mca1<-MCA(newbd, method="Burt", graph=FALSE)
cats = apply(newbd, 2, function(x) nlevels(as.factor(x)))

mca1_vars_df = data.frame(res.mca1$var$coord, Variable = rep(names(cats), cats))
mca1_obs_df = data.frame(res.mca1$ind$coord)

ggplot(data = mca1_vars_df, aes(x = Dim.1, y = Dim.2)) +
  geom_hline(yintercept = 0, colour = "gray70") +
  geom_vline(xintercept = 0, colour = "gray70") +
  geom_point(colour = "gray50", alpha = 0.7) +
  geom_density2d(colour = "gray80") +
  geom_text(data = mca1_vars_df, 
            aes(x = Dim.1, y = Dim.2, 
                label = rownames(mca1_vars_df), colour = Variable), cex = 3) +
  
  ggtitle("MCA plot of variables using R package FactoMineR") +
  scale_colour_discrete(name = "Variable")+ 
  xlim(-3,1.5) + 
  ylim(-1.5,2)
```
CAL ANALITZAR. Es veu poc, aixi que es passa a anlitzar per cada variable.

````{r}
plotellipses(res.mca,keepvar = "all", axes = c(1, 2))
plotellipses(res.mca,keepvar = "all", axes = c(1, 2))[1] #GENDER. COMO SE INTERPRETA ESTE GRÁFICO

for(i in 1:5) {   # 1a dimension
  for (j in 1:5) {  # 2a dimension
    if (i != j) {
      grafico <- plotellipses(res.mca,keepvar = "all", axes = c(i, j))[8] #GENDER. COMO SE INTERPRETA ESTE GRÁFICO
      plot(grafico)
    }
  }
}


````
CAL ANALITZAR. agrupar variables que tienen alta asociación, en 2 o 3 grupos. 