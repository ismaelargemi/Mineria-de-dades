---
title: "Untitled"
author: "Iker Meneses Sales"
date: "2023-10-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include = F, warning=F, include=F}
library(MASS)
library(dplyr)
library(withr)
library(kableExtra)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(pROC)
library(doBy)
library(caret)
```

```{r}
load("C:/Users/iker1/Downloads/Dades preprocessades.RData")
```

En primer lugar, estandarizamos los datos usando la función de R `scale()`:

```{r, warning = F}
summaryBy(log_AMT_INCOME_TOTAL ~ TARGET, data = df_preprocessed, FUN = c(mean, sd, min, max))

x = c("CNT_FAM_MEMBERS", "log_AMT_INCOME_TOTAL", "log_AMT_GOODS_PRICE", "AGE_YEARS", "RATIO_CREDIT_INCOME", "RATIO_ANNUITY_CREDIT", "DTI_RATIO")

df_prep_num = df_preprocessed[,x]
df_prep_num = scale(df_prep_num)

pc1 = prcomp(df_prep_num, scale=TRUE)

pca_var = fviz_pca_var(pc1, repel = T, labelsize = 2)
pca_ind = fviz_pca_ind(pc1, label = "none") +
  xlim(-10,10) +
  ylim(-6,6)

grid.arrange(pca_var, pca_ind, ncol = 2)
```

```{r}
df_lda = data.frame(df_prep_num, TARGET = df_preprocessed$TARGET)
```

En primer lugar, se realizará la partición del dataset en train y test. Para ello, se reservará el 80% del total de datos para entrenar el modelo y el 20% para testear el modelo discriminante resultante.

```{r}
set.seed(2023)
ind = sample(1:5000, 0.8*5000, replace = F)

train = df_lda[ind,]
test = df_lda[-ind,]

x_train = train[!names(train) %in% "TARGET"]
y_train = train$TARGET

x_test = test[!names(test) %in% "TARGET"]
y_test = test$TARGET
```


Así pues, finalmente, se destinarán 4000 observaciones al proceso de training y 1000 para el testing. Seguidamente, se muestra la distribución de las proyecciones de cada grupo en el discriminante encontrado:

```{r}
linear_discriminant = lda(x_train, y_train)
plot(linear_discriminant)
```

Como se puede apreciar, el discriminante encontrado no realiza un buen trabajo: se puede apreciar cómo los histogramas se solapan de forma prácticamente perfecta. Si se observa la matriz de confusión resultante, se obtiene el siguiente resultado:

```{r}
predictions = linear_discriminant %>% predict(x_train)
pred1 = predictions$posterior[,2]


g = roc(y_train,pred1)
# plot(g,print.thres = T)
thres = coords(g, "best", ret = "threshold")[1,1]

predictions_test = linear_discriminant %>% predict(x_test)

pred2 = predictions_test$posterior[,2]
pred2 = factor(ifelse(pred2>thres, 1, 0))

MC = confusionMatrix(pred2, y_test)
MC
```

En este caso, la matriz de confusión se ha optimizado usando el threshold proveniente de la curva ROC que maximizara la suma de sensibilidad + especificidad, el cual se sitúa en `r round(thres,4)`. Como ya se podía prever, los resultados son muy pobres: únicamente se ha obtenido una accuracy del `r round(MC$overall["Accuracy"]*100,4)`%, segregado en una sensibilidad de un `r round(MC$byClass["Sensitivity"]*100,4)`% y una especificidad del `r round(MC$byClass["Specificity"]*100,4)`%.

Sin embargo, se sabe que el LDA puede presentar problemas en el momento en el que las variables no presentan normalidad o cuando las matrices de covarianzas son diferentes para cada grupo. Como ya se apreció en la descriptiva post-preprocessing, muchas de nuestras variables no presentaban normalidad, de forma que esto podría ser un problema de cara al uso del LDA. Es por eso por lo que se ha decidido realizar un QDA (Quadratic Discriminant Analysis) con el objetivo de corregir dichos problemas y mejorar la performance del LDA.

**QDA**

Así pues, repitiendo el procedimiento seguido anteriormente en el LDA, toca repetir los mismos pasos para este modelo. De esta forma, los resultados obtenidos son los siguientes:

```{r}
quadratic_discriminant = qda(x_train, y_train)

predictions = quadratic_discriminant %>% predict(x_train)
pred1 = predictions$posterior[,2]

g = roc(y_train,pred1)
plot(g,print.thres = T)
thres = coords(g, "best", ret = "threshold")[1,1]

predictions_test = linear_discriminant %>% predict(x_test)

pred2 = predictions_test$posterior[,2]
pred2 = factor(ifelse(pred2>thres, 1, 0))

MC = confusionMatrix(pred2, y_test)
MC
```

Como se puede apreciar, los resultados obtenidos usando QDA son aún peor a los que se obtuvieron en el discriminante lineal. Si bien es cierto que la precisión del modelo es del `r round(MC$overall["Accuracy"]*100,4)`%, hay una gran disparidad entre la sensibilidad (`r round(MC$byClass["Sensitivity"]*100,4)`%) y la especificidad (`r round(MC$byClass["Specificity"]*100,4)`%). Estos resultados indican que el modelo es incapaz de detectar a los clientes que podrían ser potencialmente morosos. De esta forma, este modelo debería ser rechazado por los pobres resultados que proporciona.

