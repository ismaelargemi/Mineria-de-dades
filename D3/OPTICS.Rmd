---
title: "OPTICS"
author: "Mireia Bolívar"
date: "2023-10-22"
output: html_document
---


```{r}
# Cargamos las librerias necesarias
library(cluster)
library(fpc)
library(pracma)
library(factoextra)
library(dbscan)

# =============================================================================
### Generamos una semilla para poder ejecutar los datos
set.seed(04102022)

# ==============================================================================
### Creamos la base de datos que vamos a utilizar para detectar los grupos

datos <- get(load("C:/Users/mibor/OneDrive/Documentos/GitHub/Mineria-de-dades/D3/Dades preprocessades.RData"))

### Nos quedamos únicamente con las variables numéricas

mydata <- df_preprocessed
mydata$AMT_INCOME_TOTAL <- NULL
mydata$AMT_CREDIT <- NULL
mydata$AMT_ANNUITY <- NULL
mydata$AMT_GOODS_PRICE <- NULL


rm(df_preprocessed)

Objectos <- sapply(mydata, class)
Numeriques <- names(Objectos)[which(Objectos%in%c("numeric"))]

dd <- mydata[,Numeriques]
dd<- dd[,c(2:8)]


```



# =============================================================================
# OPTICS

OPTICS (Ordering Points To Identify the Clustering Structure), es otro algoritmo de clustering utilizado en mineria de datos y análisis de datos para descubrir patrones y estructuras en conjuntos de datos; siendo su objetivo principal descubrir grupos de puntos que están densamente agrupados en el espacio de características. Fue propuesto como una mejora del algoritmo DBSCAN, dado que este tiene problemas con las fronteras. 

El algoritmo OPTICS comienza identificando los puntos centrales (core points) en el conjunto de datos (llamado `minPts`) dentro de un radio específico (llamado `eps`). Dado que una de sus limitaciones es la elección adecuada de estos parámetros, ja que son cruciales para obtener resultados óptimos, a continuación se optimiza su búsqueda:

## Búsqueda de los parámetros óptimos

**Optimizamos la búsqueda de parámetros para epsilon y minPts en Optics**

```{r}
#Cargamos las librerias necesarias:
library(doParallel) #trabaja en paralelo al coger nuestro ordenador y dividirlo en dos (bigdata)
library(foreach) #para hacer bucles
```

Primeramente, definimos los valores que se van a probar para eps y minPts, creando una cuadrícula de parámetros y, seguidamente, se establece el número de núcleos (cores) a utilizar para la optimización en paralelo, que se calcula automáticamente.
```{r}
eps_values <- seq(0.1, 1.0, by = 0.1)
minPts_values <- seq(5, 20, by = 5)

# Cuadrícula de búsqueda de los valores de eps y minPts
grid <- expand.grid(eps = eps_values, minPts = minPts_values)

### Establecemos el número de núcleos que se van a usar para realizar la optimización en paralelo
#calcula cuantos cores tenemos en nuestro ordenador, en este caso ocho
cores <- detectCores()
registerDoParallel(cores = cores)
```

**Función para ejecutar OPTICS con una combinación de parámetros y calcular el coeficiente de silueta:**

```{r}
run_optics <- function(data, eps, minPts) {
  optics <- dbscan::optics(data, eps = eps, minPts = minPts)
  res <- dbscan::extractDBSCAN(optics, eps_cl = eps)
  sil <- cluster::silhouette(res$cluster, dist(data))
  return(ifelse(is.na(sil), sil, mean(sil[, 3])))
}
### Con esta función nos permitirá luego paralelizar el proceso

### Ejecutar la cuadrícula de búsqueda en paralelo para la función dada
results <- foreach(i = 1:nrow(grid), .combine = rbind) %dopar% {
  eps <- grid$eps[i]
  minPts <- grid$minPts[i]
  score <- run_optics(dd, eps, minPts)
  c(eps, minPts, score)
} #objetivo: maximizar o minimizar el siluette.

results <- results[, c(1:3)]

### Seleccionamos la combinación de parámetros que produjo el mejor resultado
best_params <- grid[which.max(results[, 3]), ]
best_params
```
Como vemos, después del proceso iterativo, la combinación de resultados más óptima ha sido un radio (`eps`) de 0.5 con un mínimo de 5 puntos (`minPts`). 

Así mismo, a continuación creamos el modelo OPTICS con los parámetros óptimos encontrados y observamos su reachability plot:

```{r}
### generamos el optics maximizado
optics <- dbscan::optics(dd, eps = best_params$eps, minPts = best_params$minPts)

plot(optics, reachability=TRUE)
```

El gráfico de reachability (alcance) que acabamos de generar, es una herramienta para visualizar la estructura de clusters identificados.

En los gráficos de reachability, cada punto representa un objeto de datos y la altura de la curva indica la distancia a la que se encuentra el objeto más cercano dentro del mismo clúster. Los valles en la curva indican la presencia de clusters, ya que los puntos dentro de un mismo clúster tienden a estar más cerca entre sí que con puntos de otros clústers. 

Así pues, como se puede observar, no podemos ser capaces de interpretar el reachability plot resultante. Esto se debe a que nuestra base de datos puede no ser apropiada para utilizar técnicas de clustering basadas en densidad. 

**MÉTODO DE LA SILUETA**
Otra de las maneras para encontrar los valores óptimos de los parámetros necesarios es a partir del método de la silueta.

En esta sección se ejecutará OPTICS con diferentes valores de `eps`y se calcularán la medida de silueta para cada valor. Luego, se graficará esta medida en función de epsilon y se identificará su valor óptimo. 

```{r}
### Metodo de la silueta

#### Ejecutar OPTICS para diferentes valores de eps
eps_values <- seq(0.1, 1, by = 0.1)
optics_results <- lapply(eps_values, function(e) optics(dd, eps = e, minPts = 5))

#### Obtener los agrupamientos para cada valor de eps
clusters <- lapply(optics_results, function(x) extractDBSCAN(x, eps = x$eps))

#### Calcular la medida de silhouette promedio para cada valor de eps
silhouette_avg <- sapply(clusters, function(x) mean(cluster::silhouette(x$cluster, dist(dd))))

# Graficar la medida de silhouette promedio en función de eps
plot(eps_values, silhouette_avg, type = "b", pch = 20, main = "Silhouette Plot")

# Agregar una línea vertical en el valor óptimo de eps, el que maximiza la silhoutte:
opt_eps <- eps_values[which.max(silhouette_avg)]

abline(v = opt_eps, lty = 2, col = "red")
```

Como se puede apreciar, al agregar una línea vertical en el valor óptimo de epsilon, vemos que se aconseja cortar en 1, valor que maximiza la silhouette.

Por último, entramos en la etapa posterior al cálculo de la estructura de clusters utilizando OPTICS, que consiste en extraer y visualizar los resultados del clustering, donde a partir de la variable `opt_eps` se determinará como se corta la curva de alcance para identificar los clusters. 

```{r}
opt_eps #en este caso igual a uno
res <- dbscan::extractDBSCAN(optics, eps_cl = opt_eps)

### el negro es ruido
plot(res)
```
Con `plot(res)` se genera un gráfico que visualiza los clusters obtenidos. Los puntos de datos se colorean de acuerdo con los clusters a los que pertenecen, y los puntos que se consideran ruido se muestran en negro.

De igual manera que pasaba en el reachability plot anterior, no somos capaces de identificar ningún resultado. 

Finalmente, visualizamos el gráfico con los grupos creados en forma de polígonos convexos. Estos polígonos nos ayudan a delimitar visualmente la extensión de cada clúster.
```{r}
dbscan::hullplot(dd, res)
#res$cluster
table(res$cluster)
#Una vez tenemos los resultados del clústering, guardarlos en un objeto para su posterior análisis o referencia, 

```
Por un lado, los resultados obtenidos a partir del gráfico no nos permiten extraer resultados. 

Por otro lado, la tabla obtenida nos resume el número de puntos en cada cluster. Así pues, observamos como aunque nos divide los datos en tres clusters, el grupo 0 es el dominante, con 4992 puntos de datos, dejando 5 puntos para el clúster 1 y 3 para el clúster 2, siendo esta una mala agrupación para nuestros datos.  


### Conclusión

En conclusión, aunque las técnicas utilizadas nos hayan ayudado a encontrar unos buenos parámetros para poder agrupar nuestros datos de la manera más óptima, vemos como estos resultados nos ayudan a respaldar aún más el hecho de que nuestra base de datos no es válida para técnicas de clustering basados en densidad, posiblemente por no tener una distribución de densidad variable. 

Las técnicas de clustering basadas en densidad asumen que los clústers se forman en regiones de alta densidad de datos. Por lo tanto, si nuestros datos no tienen una distribución de densidad variable (puntos uniformemente distribuidos o clusters sin una densidad significativamente mayor que el fondo), las téncicas de clustering basadas en densidad pueden no ser efectivas.

Así pues, ni DBSCAN ni OPTICS nos permiten extraer un buen análisis de nuestra base de datos. 