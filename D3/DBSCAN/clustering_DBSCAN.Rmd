---
output: pdf_document
header-includes:
- \usepackage{fullpage} 
- \usepackage[spanish]{babel}
- \setlength{\headsep}{7mm} 
- \usepackage[linktoc=page]{hyperref}
- \usepackage{fancyhdr}
- \usepackage{floatrow}
- \floatsetup[figure]{capposition=top}
- \floatsetup[table]{style=plaintop}
- \usepackage{float}
- \floatplacement{figure}{H}
- \newcommand{\beginsupplement}{
  \setcounter{table}{33}  
  \renewcommand{\thetable}{\arabic{table}} 
  \setcounter{figure}{105} 
  \renewcommand{\thefigure}{\arabic{figure}}}
- \setlength{\headheight}{13.6pt}
- \setlength{\topmargin}{-10mm}
- \rhead{Minería de Datos}
- \lhead{Entrega D3}
---

\pagenumbering{arabic}
\pagestyle{fancy}

```{=tex}
\cfoot{\thepage}
\setcounter{page}{78}
```
\beginsupplement


```{r, include=FALSE}
library(cluster)
library(fpc)
library(pracma)
library(factoextra)
library(dbscan)
library(gdata)
library(dplyr) 
library(kableExtra)
set.seed(04102022)
```
# DBSCAN

```{r, include=FALSE, echo=FALSE}
# Lectura de la base de datos
load("dades_post_pca.RData")
datos <- data[, 9:16] 
```
El algoritmo DBSCAN es un método de clústering basado en densidad de aplicaciones con ruido. Este método permite agrupar los datos cuando estos presentan formas complejas, así como es un método robusto frente a la presencia de outliers. Para realizar el algoritmo DBSCAN se emplean sólo las variables numéricas normalizadas. 

DBSCAN parte de dos parámetros que son:
- Épsilon: distancia máxima a la que debe haber otra observación para ser considerar que cumple con el criterio de "estar cerca"
- Mínimo de puntos: parámetro que controla la densidad mínima requerida para que un punto sea considerado un núcleo y se incluya en un grupo/clúster.

## Cálculo de mínimo de puntos
Para calcularlo de manera empírica, diremos que el mínimo de puntos sea igual al 0.2% - 0.25% del total de los datos teniendo en cuenta que: 

  - El mínimo será de 2 para datos que sean muy pequeños
  - El máximo será de 10 para datos con mucha información

```{r, include=FALSE}
porcentaje <- 0.00225
min_pts <- round(nrow(datos) * porcentaje) 
min_pts

# Realizamos los cortes de 2 y 10 que se mencionan anteriormente como validación
min_pts <- ifelse(min_pts <= 1, 2, min_pts)
min_pts <- ifelse(min_pts >= 10, 10, min_pts)
```
Aplicando esto, se tiene que el número mínimo de puntos sería 11, pero lo limitamos a 10 en concordancia con la literatura.
 
## Cálculo de épsilon
Se escogerá épsilon a partir del siguiente gráfico del codo, realizado con el método del k-NN. Como se han realizado otros métodos de clústering, se aplica el k-NN con el valor de K sacado de los métodos de clústerng jeráriquico, que concluyen que el número de clústers k óptimo es 2. Estas k-distancias se trazan en orden ascendente con el objetivo es determinar la “codo”, que corresponde al parámetro épsilon óptimo. A partir del siguiente gráfico del codo se puede observar el valor óptimo de épsilon.

```{r,  echo=F,fig.cap = "Gráfico del Codo para el Valor Óptimo de Épsilon", fig.show='hold',out.width="75%",out.height="75%"}
# distanciasVecinas <- dbscan::kNNdist(datos, k = 2)
# 
# ### Ordenamos los puntos de menos a mayor y lo guardamos en un vector.
# ### Cuando realicemos el gráfico elbow, será nuestro eje de las Y
#  Y <- distanciasVecinas[order(distanciasVecinas)]
# 
# ### Calculamos el índice del eje de la X
#  X <- c(0:(length(Y) - 1))
# 
# ### A continuación calculamos las pendientes
#  pendientes <- c()
#  for (i in 1:length(X)) {
# 	pendientes[i] <- (Y[i + 1] - Y[i])/(X[i+1] - X[i])
#  }
# 
#  m <- which.max(pendientes)
# primer <- gdata::first(which(pendientes >= m))
# epsilon<- Y[m] 

kNNdistplot(datos, k = 2, minPts = min_pts)
  abline(h = 4.5, lty = 2, col = "red")

epsilon=4.5
```

El valor de épsilon se decide a partir de el corte en el máximo cambio de la pendiente. En el gráfico se observa que esto se da alrededor de épsilon = 4.5.


## Resultado DBSCAN
Aplicamos el método DBSCAN con los valores extraídos: épsilon=4.5 y mínimo de puntos de 10. 
```{r, echo=FALSE}

res <- dbscan(datos, eps = epsilon, minPts = min_pts)

kbl(table(res$cluster),
      caption = "Resumen del número de puntos en cada clúster", col.names = c("Clúster", "Frecuencia de puntos"), booktabs = T) %>%
  kable_styling(position = "center", 
                latex_options = c("HOLD_position"))


```
EL resultado del DBSCAN indica que agrupa los datos en 2 clústers, y devuelve 61 puntos como outliers. 

Se presenta el gráfico de los clústers obtenidos con el DBSCAN:
```{r, echo=F,fig.cap = "Gráfico Clústers obtenidos con DBSCAN", fig.show='hold',out.width="75%",out.height="75%"}
# ### Se añade la columna clúster a mis datos.
datos$cluster <- res$cluster

### Guardo datos limpios
datos_limpios <- dplyr::filter(datos, cluster != 0)

### Guardo outliers.
outliers <- dplyr::filter(datos, cluster == 0)

### Graficamos el dbscan obtenido. Es el mismo gráfico anterior pero en PCA
fviz_cluster(object = res, data = datos, geom = "point", ellipse = FALSE,
             show.clust.cent = FALSE, pallete = "jco") +
  theme_bw() +
  theme(legend.position = "none")
```
Con estos resultados, ya se aprecia que el DBSCAN no realiza agrupaciones óptimas en estos datos, ya que la inmensa mayoría de datos se ubican en el primer clúster, y el segundo clúster contiene una proporción de datos ínfima. Esto puede ser debido a que el DBSCAN es un método que parte de las densidades, y en los datos que se agrupan con formas más simples y uniformes, como los que se tratan en este trabajo, puede no encontrar la solución ótpima, como se considera en este caso. A esta misma conclusión se llegará también con el método OPTICS, ya que también es un método de clústering basado en densidades.
