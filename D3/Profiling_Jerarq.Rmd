---
output: pdf_document
header-includes:
  - \usepackage{fullpage} 
  - \usepackage[spanish]{babel}
  - \usepackage{fancyhdr}
  - \setlength{\headsep}{7mm} 
  - \usepackage[linktoc=page]{hyperref}
---

```{=tex}
\setlength{\headheight}{13.6pt}
\setlength{\topmargin}{-10mm}

\rhead{Minería de Datos}
\lhead{Entrega D3}
```
\pagestyle{fancy}
```{=tex}
\cfoot{\thepage}
\setcounter{page}{5}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Lectura de los datos
load("Dades preprocessades.Rdata")
mydata <- df_preprocessed
mydata[,c("AMT_INCOME_TOTAL","AMT_CREDIT","AMT_ANNUITY","AMT_GOODS_PRICE",
          "DAYS_BIRTH","log_AMT_GOODS_PRICE","log_AMT_ANNUITY",
          "DIFF_CREDIT_GOODS")] <- NULL
dades <- mydata

load("data_clust.Rdata")
cluster <- mydata$cluster2
```


Con el objetivo de perfilar los grupos conseguidos mediante el algoritmo Jerárquico primero veremos la significación de las variables para los grupos y después se graficarán para identificar las características definitorias de cada grupo.

A continuación se muestran los p-valores para evaluar la significación de cada variable. Primeramente de las variables categóricas y seguidamente las numéricas.

```{r}
indices_categoricas <- sapply(dades, is.factor)
p_values <- numeric(length(dades))

# Realiza pruebas de chi-cuadrado para las variables categóricas
for (i in which(indices_categoricas)) {
  variable_categorica <- dades[, i]
  cross_table <- table(variable_categorica, cluster)
  chi_square_result <- chisq.test(cross_table)
  p_values[i] <- chi_square_result$p.value
}


# Muestra los resultados
p_values_categoricas <- data.frame(
  Variable = names(dades)[indices_categoricas],
  P_Value = p_values[indices_categoricas]
)
print(p_values_categoricas)

```


```{r}
library(car)
# Identifica las variables categóricas (factores)
variables_categoricas <- sapply(dades, is.factor)

# Filtra las variables numéricas
variables_numericas <- dades[!variables_categoricas]
# Inicializa un objeto para almacenar los p valores de la ANOVA
p_values_numericas <- list()

# Realiza un ANOVA para cada variable numérica en función de cluster6 y cluster3
for (i in 1:ncol(variables_numericas)) {
  variable_name <- names(variables_numericas)[i]
  
  formula_cluster <- as.formula(paste(variable_name, " ~ cluster"))
  anova_result_cluster <- Anova(lm(formula_cluster, data = variables_numericas))
  
  # Almacena los p-valores de la ANOVA en p_values_anova
  p_values_numericas[[variable_name]] <- c(Cluster = anova_result_cluster[["Pr(>F)"]][1])
}

# Muestra el objeto con los p-valores de la ANOVA
print(p_values_numericas)
```

Elaboramos una tabla donde se indica con 1 si se considera variable significativa para el clúster y 0 en caso contrario.

```{r}
# Función para evaluar significancia de p-valores
evaluate_p_values <- function(p_values, alpha = 0.05) {
  significance <- ifelse(p_values <= alpha, 1, 0)
  return(significance)
}

# Evalúa significancia de p-valores para variables numéricas y categóricas
significance_numericas <- evaluate_p_values(p_values_numericas)
significance_categoricas <- evaluate_p_values(p_values_categoricas[,2])

# Resultados:
print("Significancia de p-valores para variables numéricas:")
print(significance_numericas)

names(significance_categoricas) <- p_values_categoricas[,1]
print("Significancia de p-valores para variables categóricas:")
print(significance_categoricas)
```

Podemos observar que solo se descarta una variable, pero al analizar gráficamente, podremos identificar qué variables son las que realmente aportan información significativa.

Se grafican las variables según clúster. Para las variables numéricas se mostrará la media grupal y la media global; para las variables categóricas se mostrarán las cantidades de cada nivel de la variable categórica por clúster.

```{r}
# install.packages("FactoMineR")
# library(FactoMineR)
# dadesc <- cbind(dades,factor(cluster))
# resul <- catdes(dadesc,num.var=16,proba=0.05)
# resul$test.chi2 # Da el mismo resultado que el anterior.
# resul$quanti # Sign de la var numérica por cada clúster. Todos Significativos. 
# resul$category #Solo útil para saber si el nivel explica el clúster.
```

```{r}
library(ggplot2)
colores <- scales::brewer_pal(palette = "Set1")(length(unique(cluster)))
```

```{r}
ggplot(data = dades, aes(x = cluster, y = dades$OWN_CAR_AGE)) + 
  geom_bar(stat = "summary", fun = "mean", fill= colores) +
  coord_cartesian(ylim=c(8,12))+
  geom_hline(yintercept = mean(dades$OWN_CAR_AGE)) +
  labs(title = "Medias de la Edad en años del coche del cliente por clúster respecto la media global" , y = "Media", x = "Clúster") 
```

En lo que a la edad del coche para cada cliente respecta, vemos como el clúster 5 se caracteriza por tener una media de edad de coche mucho menor que los otros clústeres. Tiene los coches más nuevos, es decir, con menos años.


```{r}
ggplot(data = dades, aes(x = cluster, y = dades$CNT_FAM_MEMBERS)) +
  geom_bar(stat = "summary", fun = "mean", fill= colores) +
  geom_hline(yintercept = mean(dades$CNT_FAM_MEMBERS)) +
  labs(title = "Medias del Número de familiares del cliente por clúster respecto la media global" , y = "Media", x = "Clúster")
```

Los clústeres 1 y 4 se caracterizan por tener el menor número de familiares. Por otro lado, el 2 y 3 tienen el mayor número de familiares.

```{r}
ggplot(data = dades, aes(x = cluster, y = dades$log_AMT_INCOME_TOTAL)) +
  geom_bar(stat = "summary", fun = "mean", fill= colores) +
  coord_cartesian(ylim=c(11,12.5))+
  geom_hline(yintercept = mean(dades$log_AMT_INCOME_TOTAL)) +
  labs(title = "Medias del logaritmo de los Ingresos totales del cliente por clúster respecto la media global" , y = "Media", x = "Clúster") 
```

A partir del gráfico, se observa que en los ingresos totales el clúster 1 se caracteriza por tener el menor número de ingresos y el clúster 3 el que mayor los tiene. No obstante, no hay diferencias muy grandes entre ellos debido a que es el logaritmo de estos ingresos y la interpretación queda afectada.

```{r}
ggplot(data = dades, aes(x = cluster, y = dades$log_AMT_CREDIT)) +
  geom_bar(stat = "summary", fun = "mean", fill= colores) +
  coord_cartesian(ylim=c(12.5,13.5))+
  geom_hline(yintercept = mean(dades$log_AMT_CREDIT)) +
  labs(title = "Medias del Importe de crédito del préstamo por clúster respecto la media global" , y = "Media", x = "Clúster")

```

En el importe de crédito por préstamo se aprecia como el clúster 4 y 1 son los que más se diferencian, teniendo un importe menor. En cambio, el clúster 3 y 4 tienen un importe mayor que el resto.

```{r}
ggplot(data = dades, aes(x = cluster, y = dades$AGE_YEARS)) +
  geom_bar(stat = "summary", fun = "mean", fill= colores) +
  coord_cartesian(ylim=c(20,60))+
  geom_hline(yintercept = mean(dades$AGE_YEARS)) +
  labs(title = "Medias de la Edad por clúster respecto la media global" , y = "Media", x = "Clúster")

```

El clúster 1 se caracteriza por ser el grupo con individuos de más edad, en otras palabras, es el clúster con los individuos más mayores.

```{r}
ggplot(data = dades, aes(x = cluster, y = dades$RATIO_CREDIT_INCOME)) +
  geom_bar(stat = "summary", fun = "mean", fill= colores) +
  coord_cartesian(ylim=c(2,5))+
  geom_hline(yintercept = mean(dades$RATIO_CREDIT_INCOME)) +
  labs(title = "Medias del Ratio del Importe del préstamo por clúster respecto la media global" , y = "Media", x = "Clúster")
```

En el número de años que se tarda en devolver el crédito, se aprecia como los más rápidos son los sujetos del clúster 4. Contrariamente, el grupo 1 y 2 son los que más se demoran. 

```{r}
ggplot(data = dades, aes(x = cluster, y = dades$RATIO_ANNUITY_CREDIT)) +
  geom_bar(stat = "summary", fun = "mean", fill= colores) +
  coord_cartesian(ylim=c(0.04,0.06))+
  geom_hline(yintercept = mean(dades$RATIO_ANNUITY_CREDIT)) +
  labs(title = "Medias del Ratio de la Anualidad del préstamo por clúster respecto la media global" , y = "Media", x = "Clúster")

```

El clúster que se diferencia es el 4, con una Ratio entre la anualidad del préstamo y el crédito total solicitado.

```{r}
ggplot(data = dades, aes(x = cluster, y = dades$DTI_RATIO)) +
  geom_bar(stat = "summary", fun = "mean", fill= colores) +
  coord_cartesian(ylim=c(0.1,0.25))+
  geom_hline(yintercept = mean(dades$DTI_RATIO)) +
  labs(title = "Medias de la Capacidad de cliente para pagar la annuity con sus ingresos por clúster respecto la media global" , y = "Media", x = "Clúster")
```
La ratio mide la capacidad del cliente para pagar la anualidad de su préstamo en relación con sus ingresos. Por ende, los menos capaces son los individuos del clúster 2.

```{r}
ggplot(data = dades, aes(x = cluster, fill = dades$TARGET)) +
  geom_bar(position = "dodge") +
  labs(title = "Gráfico de la distribución de la variable respuesta", y = "Freq", x = "Clúster") +
  theme(legend.position = "top") + guides(fill = guide_legend(title = NULL))
```
El algoritmo no ha logrado encontrar una estructura o agrupamiento en los datos que permita caracterizar nuestros grupos por la variable objetivo. Sin embargo, se observa una particularidad en la proporción de morosidad en el grupo 4, donde hay más clientes morosos que no morosos. Esto contrasta con la distribución de frecuencias en el resto de los grupos.

```{r}
ggplot(data = dades, aes(x = cluster, fill = dades$CODE_GENDER)) +
  geom_bar(position = "dodge") +
  labs(title = "Gráfico de la distribución del Género respecto el Clúster", y = "Freq", x = "Clúster") +
  theme(legend.position = "top") + guides(fill = guide_legend(title = NULL))
```

En la distribución del género de los individuos según el clúster, se observa como los grupos 1, 2 y 5 están formados por mujeres, el 3 por hombres y el 4 por hombres y mujeres a partes iguales.

```{r}
ggplot(data = dades, aes(x = cluster, fill = dades$NAME_INCOME_TYPE)) +
  geom_bar(position = "dodge") +
  labs(title = "Gráfico de la distribución del Tipo de ingresos respecto el Clúster", y = "Freq", x = "Clúster") +
  theme(legend.position = "top") + guides(fill = guide_legend(title = NULL))
```

El primer grupo es el de los pensionistas y el quinto es el de los comerciantes asociantes.

```{r}
ggplot(data = dades, aes(x = cluster, fill = dades$NAME_EDUCATION_TYPE)) +
  geom_bar(position = "dodge") +
  labs(title = "Gráfico de la distribución del Nivel de estudios del cliente respecto el Clúster", y = "Freq", x = "Clúster") +
  theme(legend.position = "top") + guides(fill = guide_legend(title = NULL))
```

No hay diferencias con la distribución.

```{r}
ggplot(data = dades, aes(x = cluster, fill = dades$NAME_FAMILY_STATUS)) +
  geom_bar(position = "dodge") +
  labs(title = "Gráfico de la distribución del Estado civil respecto el Clúster", y = "Freq", x = "Clúster") +
  theme(legend.position = "top") + guides(fill = guide_legend(title = NULL))
```

En el Clúster 4 se incluye a personas que no están casadas o que tienen una unión civil.

```{r}
ggplot(data = dades, aes(x = cluster, fill = dades$OCCUPATION_TYPE)) +
  geom_bar(position = "dodge") +
  labs(title = "Gráfico de la distribución de la Actividad laboral respecto el Clúster", y = "Freq", x = "Clúster") +
  theme(legend.position = "top") + guides(fill = guide_legend(title = NULL))
```

El grupo uno es el de los individuos que no trabajan, hecho que coincide con que también sea el grupo de los pensionistas. Por otra parte, el grupo dos tiene más proporción de "mid skill workers".

```{r}
ggplot(data = dades, aes(x = cluster, fill = dades$ORGANIZATION_TYPE)) +
  geom_bar(position = "dodge") +
  labs(title = "Gráfico de la distribución del Tipo de organización donde trabaja el cliente respecto el Clúster", y = "Freq", x = "Clúster") +
  theme(legend.position = "top") + guides(fill = guide_legend(title = NULL))
```

Respecto al grupo uno no se puede saber a que tipo de organización pertenecen porque no trabajan, son los pensionistas. El resto sigue una distribución muy parecida aunque el grupo dos parece estar más dedicado a la educación que los otros.

```{r}
ggplot(data = dades, aes(x = cluster, fill = dades$REGION_RATING_CLIENT)) +
  geom_bar(position = "dodge") +
  labs(title = "Gráfico de la distribución de la Calificación de la región donde vive el cliente respecto el Clúster", y = "Freq", x = "Clúster") +
  theme(legend.position = "top") + guides(fill = guide_legend(title = NULL))
```
No hay grandes diferencias en la distribución de  la clasificación por región.

Conclusiones:

Clúster 1: Se caracteriza por individuos con pocos familiares y menor número de ingresos. Es el grupo de las mujeres de mayor edad pensionistas, las cuales tardan más en devolver el préstamo.

Clúster 2: Son mujeres, con una alta cantidad de familiares y mayor cantidad de importe del préstamo. Son los que peor capacidad de devolver el préstamo tienen, es decir, los que más se demoran en devolverlo. Proporcionalmente cuentan con más "mid skill workers".

Clúster 3: Es el grupo de los hombres con mayor número de ingresos y con más cantidad de familiares.

Clúster 4: En este clúster están los individuos con menor importe de crédito por préstamo, ratio de anualidad más grande además de ser los más rápidos en devolver el crédito. Se caracteriza por estar compuesto en la misma proporción tanto de hombres como de mujeres, con pocos familiares. Los individuos están solteros o casados civilmente. 

Clúster 5: Este último grupo está formado por las mujeres con mayor número de crédito por préstamo. Caracterizadas por tener coches más nuevos y ser "commercial associates".


Comparación Profiling K-means y Jerárquico

Se destaca una diferencia en el número de clústers entre ambos métodos, con 3 clústers para K-means y 5 para el clústering jerárquico.

En el enfoque de clustering jerárquico, se logra obtener perfiles altamente específicos y fácilmente distinguibles para cada grupo, en contraste con los perfiles obtenidos a través de la metodología k-means.

En la metodología k-means, se observa que la explicación de los grupos se limita exclusivamente a variables numéricas, sin considerar ninguna variable categórica. Este enfoque numérico puro resulta en perfiles menos detallados, ya que no refleja la variabilidad explicada por las variables categóricas. Este aspecto contribuye a que los perfiles generados por k-means sean menos distintivos y caracterizados en comparación con los obtenidos mediante el clustering jerárquico.



